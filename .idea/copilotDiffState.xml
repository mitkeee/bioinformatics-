<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/CSV_HEADER_DESCRIPTION.txt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/CSV_HEADER_DESCRIPTION.txt" />
              <option name="originalContent" value="================================================================================&#10;CSV OUTPUT FILE HEADER DESCRIPTION&#10;================================================================================&#10;&#10;This document describes the columns in the CSV files generated by the protein&#10;burial analysis pipeline (e.g., 3pte_results.csv, 4d05_results.csv, etc.)&#10;&#10;Generated by: protein_burial_analysis.py and extract_ca.py&#10;Location: results/[protein_name]_results.csv&#10;&#10;================================================================================&#10;COLUMN DESCRIPTIONS&#10;================================================================================&#10;&#10;1. res_id&#10;   - Residue identifier (3-letter amino acid code)&#10;   - Type: String&#10;   - Example: ALA, ASP, LEU, PRO, GLY, VAL, HIS, THR&#10;   - Description: Standard amino acid residue name&#10;&#10;2. res_num&#10;   - Residue number (sequence position)&#10;   - Type: Integer&#10;   - Example: 1, 2, 3, 4, 5...&#10;   - Description: Sequential position of residue in the protein chain&#10;&#10;3. dssp_asa&#10;   - DSSP Accessible Surface Area&#10;   - Type: Float&#10;   - Units: Ų (square Angstroms)&#10;   - Range: 0.0 to ~200.0&#10;   - Description: Relative accessible surface area calculated by DSSP&#10;                  (normalized by residue type max ASA)&#10;   - Missing values: Empty if DSSP data unavailable&#10;&#10;4. dssp_class&#10;   - DSSP burial classification&#10;   - Type: Integer (0 or 1)&#10;   - Values: 0 = Interior (buried)&#10;            1 = Exterior (exposed)&#10;   - Description: Binary classification based on DSSP ASA threshold&#10;   - Missing values: Empty if DSSP data unavailable&#10;&#10;5. stride_asa&#10;   - STRIDE Accessible Surface Area&#10;   - Type: Float&#10;   - Units: Ų (square Angstroms)&#10;   - Range: 0.0 to ~200.0&#10;   - Description: Relative accessible surface area calculated by STRIDE&#10;                  (normalized by residue type max ASA)&#10;   - Missing values: Empty if STRIDE data unavailable&#10;&#10;6. stride_class&#10;   - STRIDE burial classification&#10;   - Type: Integer (0 or 1)&#10;   - Values: 0 = Interior (buried)&#10;            1 = Exterior (exposed)&#10;   - Description: Binary classification based on STRIDE ASA threshold&#10;   - Missing values: Empty if STRIDE data unavailable&#10;&#10;7. ncps_sphere_6&#10;   - Neighbor Count (6Å sphere)&#10;   - Type: Integer&#10;   - Range: 0 to ~30&#10;   - Description: Number of CA atoms within 6Å radius sphere&#10;                  (excludes self and immediate neighbors i±1)&#10;   - Higher values = more densely packed (interior)&#10;   - Missing values: Empty if calculation failed&#10;&#10;8. ncps_sphere_6_uni&#10;   - Uniformity score at 6Å radius&#10;   - Type: Float&#10;   - Range: 0.0 to 1.0&#10;   - Description: Measure of uniform distribution of neighbors in 6Å sphere&#10;                  Higher values = more uniform distribution (typical of interior)&#10;                  Lower values = non-uniform distribution (typical of surface)&#10;   - Calculation: Based on angular distribution of neighbor vectors&#10;   - Missing values: Empty if too few neighbors or calculation failed&#10;&#10;9. ncps_sphere_10&#10;   - Neighbor Count (10Å sphere)&#10;   - Type: Integer&#10;   - Range: 0 to ~60&#10;   - Description: Number of CA atoms within 10Å radius sphere&#10;                  (excludes self and immediate neighbors i±1)&#10;   - Higher values = more densely packed (interior)&#10;   - Missing values: Empty if calculation failed&#10;&#10;10. ncps_sphere_10_uni&#10;    - Uniformity score at 10Å radius&#10;    - Type: Float&#10;    - Range: 0.0 to 1.0&#10;    - Description: Measure of uniform distribution of neighbors in 10Å sphere&#10;                   Higher values = more uniform distribution (typical of interior)&#10;                   Lower values = non-uniform distribution (typical of surface)&#10;    - Calculation: Based on angular distribution of neighbor vectors&#10;    - Missing values: Empty if too few neighbors or calculation failed&#10;&#10;11. ncps_class&#10;    - Neighbor Count Predicted Clasification&#10;    - Type: Integer (0 or 1)&#10;    - Values: 0 = Interior (buried)&#10;             1 = Exterior (exposed)&#10;    - Description: Classification based on neighbor count and uniformity metrics&#10;                   Uses z-score thresholds and homogeneity measures&#10;    - Algorithm: Rule-based classification from extract_ca.py&#10;&#10;12. dssp_ss&#10;    - DSSP Secondary Structure&#10;    - Type: String (single character)&#10;    - Values: H = Alpha helix&#10;             E = Beta strand&#10;             T = Turn&#10;             S = Bend&#10;             G = 3-10 helix&#10;             B = Beta bridge&#10;             I = Pi helix&#10;             - = Coil/loop (no structure)&#10;    - Description: Secondary structure assignment by DSSP&#10;    - Missing values: '-' if DSSP data unavailable&#10;&#10;13. stride_ss&#10;    - STRIDE Secondary Structure&#10;    - Type: String (single character)&#10;    - Values: H = Alpha helix&#10;             E = Beta strand&#10;             T = Turn&#10;             G = 3-10 helix&#10;             B = Beta bridge&#10;             P = Polyproline II helix&#10;             - = Coil/loop (no structure)&#10;    - Description: Secondary structure assignment by STRIDE&#10;    - Missing values: '-' if STRIDE data unavailable&#10;&#10;================================================================================&#10;NORMALIZED DATA FILES&#10;================================================================================&#10;&#10;For machine learning analysis, normalized versions are also generated:&#10;&#10;File: results/decision_tree/combined_normalized.csv&#10;&#10;Additional columns (z-score normalized per protein):&#10;- stride_asa_norm: Z-score normalized STRIDE ASA&#10;- ncps_sphere_6_norm: Z-score normalized neighbor count (6Å)&#10;- ncps_sphere_10_norm: Z-score normalized neighbor count (10Å)&#10;- ncps_sphere_6_uni_norm: Z-score normalized uniformity (6Å)&#10;- ncps_sphere_10_uni_norm: Z-score normalized uniformity (10Å)&#10;- protein: Protein identifier (3PTE, 4d05, 6wti, 7upo)&#10;&#10;Z-score normalization formula: (value - mean) / std&#10;Applied per protein to account for size differences.&#10;&#10;================================================================================&#10;NOTES&#10;================================================================================&#10;&#10;1. Ground Truth: DSSP and STRIDE are considered ground truth reference methods&#10;   for burial classification and secondary structure.&#10;&#10;2. Missing Values: Empty cells indicate data unavailable (e.g., if DSSP/STRIDE&#10;   could not process that residue or calculation failed).&#10;&#10;3. Classification Thresholds:&#10;   - Interior (buried): Low ASA, high neighbor count, high uniformity&#10;   - Exterior (exposed): High ASA, low neighbor count, low uniformity&#10;&#10;4. Usage: These files are used for:&#10;   - Decision tree classification (decision_tree_zscore_analysis.py)&#10;   - Cross-validation analysis (cross_validation_analysis.py)&#10;   - Performance comparison against reference methods&#10;   - Feature importance analysis&#10;&#10;5. File Generation:&#10;   - Run: python protein_burial_analysis.py&#10;   - Or: python extract_ca.py [pdb_file]&#10;&#10;================================================================================&#10;EXAMPLE ROW&#10;================================================================================&#10;&#10;res_id,res_num,dssp_asa,dssp_class,stride_asa,stride_class,ncps_sphere_6,...&#10;LEU,11,0.0,0,0.0,0,8,0.667,27,0.828,0,H,H&#10;&#10;Interpretation:&#10;- Leucine at position 11&#10;- DSSP ASA = 0.0 (completely buried)&#10;- DSSP class = 0 (interior)&#10;- STRIDE ASA = 0.0 (completely buried)&#10;- STRIDE class = 0 (interior)&#10;- 8 neighbors within 6Å (densely packed)&#10;- Uniformity 6Å = 0.667 (uniform distribution)&#10;- 27 neighbors within 10Å (very densely packed)&#10;- Uniformity 10Å = 0.828 (highly uniform)&#10;- Predicted class = 0 (interior) - correct!&#10;- Both DSSP and STRIDE assign alpha helix (H)&#10;&#10;This residue is clearly buried in the protein core.&#10;&#10;================================================================================&#10;&#10;" />
              <option name="updatedContent" value="================================================================================&#10;CSV OUTPUT FILE HEADER DESCRIPTION&#10;================================================================================&#10;&#10;This document describes the columns in the CSV files generated by the protein&#10;burial analysis pipeline (e.g., 3pte_results.csv, 4d05_results.csv, etc.)&#10;&#10;Generated by: protein_burial_analysis.py and extract_ca.py&#10;Location: results/[protein_name]_results.csv&#10;&#10;================================================================================&#10;COLUMN DESCRIPTIONS&#10;================================================================================&#10;&#10;1. res_id&#10;   - Residue identifier (3-letter amino acid code)&#10;   - Type: String&#10;   - Example: ALA, ASP, LEU, PRO, GLY, VAL, HIS, THR&#10;   - Description: Standard amino acid residue name&#10;&#10;2. res_num&#10;   - Residue number (sequence position)&#10;   - Type: Integer&#10;   - Example: 1, 2, 3, 4, 5...&#10;   - Description: Sequential position of residue in the protein chain&#10;&#10;3. dssp_asa&#10;   - DSSP Accessible Surface Area&#10;   - Type: Float&#10;   - Units: Ų (square Angstroms)&#10;   - Range: 0.0 to ~200.0&#10;   - Description: Relative accessible surface area calculated by DSSP&#10;                  (normalized by residue type max ASA)&#10;   - Missing values: Empty if DSSP data unavailable&#10;&#10;4. dssp_class&#10;   - DSSP burial classification&#10;   - Type: Integer (0 or 1)&#10;   - Values: 0 = Interior (buried)&#10;            1 = Exterior (exposed)&#10;   - Description: Binary classification based on DSSP ASA threshold&#10;   - Missing values: Empty if DSSP data unavailable&#10;&#10;5. stride_asa&#10;   - STRIDE Accessible Surface Area&#10;   - Type: Float&#10;   - Units: Ų (square Angstroms)&#10;   - Range: 0.0 to ~200.0&#10;   - Description: Relative accessible surface area calculated by STRIDE&#10;                  (normalized by residue type max ASA)&#10;   - Missing values: Empty if STRIDE data unavailable&#10;&#10;6. stride_class&#10;   - STRIDE burial classification&#10;   - Type: Integer (0 or 1)&#10;   - Values: 0 = Interior (buried)&#10;            1 = Exterior (exposed)&#10;   - Description: Binary classification based on STRIDE ASA threshold&#10;   - Missing values: Empty if STRIDE data unavailable&#10;&#10;7. ncps_sphere_6&#10;   - Neighbor Count (6Å sphere)&#10;   - Type: Integer&#10;   - Range: 0 to ~30&#10;   - Description: Number of CA atoms within 6Å radius sphere&#10;                  (excludes self and immediate neighbors i±1)&#10;   - Higher values = more densely packed (interior)&#10;   - Missing values: Empty if calculation failed&#10;&#10;8. ncps_sphere_6_uni&#10;   - Uniformity score at 6Å radius&#10;   - Type: Float&#10;   - Range: 0.0 to 1.0&#10;   - Description: Measure of uniform distribution of neighbors in 6Å sphere&#10;                  Higher values = more uniform distribution (typical of interior)&#10;                  Lower values = non-uniform distribution (typical of surface)&#10;   - Calculation: Based on angular distribution of neighbor vectors&#10;   - Missing values: Empty if too few neighbors or calculation failed&#10;&#10;9. ncps_sphere_10&#10;   - Neighbor Count (10Å sphere)&#10;   - Type: Integer&#10;   - Range: 0 to ~60&#10;   - Description: Number of CA atoms within 10Å radius sphere&#10;                  (excludes self and immediate neighbors i±1)&#10;   - Higher values = more densely packed (interior)&#10;   - Missing values: Empty if calculation failed&#10;&#10;10. ncps_sphere_10_uni&#10;    - Uniformity score at 10Å radius&#10;    - Type: Float&#10;    - Range: 0.0 to 1.0&#10;    - Description: Measure of uniform distribution of neighbors in 10Å sphere&#10;                   Higher values = more uniform distribution (typical of interior)&#10;                   Lower values = non-uniform distribution (typical of surface)&#10;    - Calculation: Based on angular distribution of neighbor vectors&#10;    - Missing values: Empty if too few neighbors or calculation failed&#10;&#10;11. ncps_class&#10;    - Neighbor Count Predicted Clasification&#10;    - Type: Integer (0 or 1)&#10;    - Values: 0 = Interior (buried)&#10;             1 = Exterior (exposed)&#10;    - Description: Classification based on neighbor count and uniformity metrics&#10;                   Uses z-score thresholds and homogeneity measures&#10;    - Algorithm: Rule-based classification from extract_ca.py&#10;&#10;12. dssp_ss&#10;    - DSSP Secondary Structure&#10;    - Type: String (single character)&#10;    - Values: H = Alpha helix&#10;             E = Beta strand&#10;             T = Turn&#10;             S = Bend&#10;             G = 3-10 helix&#10;             B = Beta bridge&#10;             I = Pi helix&#10;             - = Coil/loop (no structure)&#10;    - Description: Secondary structure assignment by DSSP&#10;    - Missing values: '-' if DSSP data unavailable&#10;&#10;13. stride_ss&#10;    - STRIDE Secondary Structure&#10;    - Type: String (single character)&#10;    - Values: H = Alpha helix&#10;             E = Beta strand&#10;             T = Turn&#10;             G = 3-10 helix&#10;             B = Beta bridge&#10;             P = Polyproline II helix&#10;             - = Coil/loop (no structure)&#10;    - Description: Secondary structure assignment by STRIDE&#10;    - Missing values: '-' if STRIDE data unavailable&#10;&#10;================================================================================&#10;NORMALIZED DATA FILES&#10;================================================================================&#10;&#10;For machine learning analysis, normalized versions are also generated:&#10;&#10;File: results/decision_tree/combined_normalized.csv&#10;&#10;Additional columns (z-score normalized per protein):&#10;- ncps_sphere_6_norm: Z-score normalized neighbor count (6Å) ✓ USED IN MODELS&#10;- ncps_sphere_10_norm: Z-score normalized neighbor count (10Å) ✓ USED IN MODELS&#10;- ncps_sphere_6_uni_norm: Z-score normalized uniformity (6Å) ✓ USED IN MODELS&#10;- ncps_sphere_10_uni_norm: Z-score normalized uniformity (10Å) ✓ USED IN MODELS&#10;- stride_asa_norm: Z-score normalized STRIDE ASA ✗ NOT USED (validation only)&#10;- protein: Protein identifier (3PTE, 4d05, 6wti, 7upo)&#10;&#10;Z-score normalization formula: (value - mean) / std&#10;Applied per protein to account for size differences.&#10;&#10;⚠️ IMPORTANT: Only neighbor-based features are used for classification models.&#10;   DSSP and STRIDE data are for validation/comparison ONLY.&#10;&#10;================================================================================&#10;NOTES&#10;================================================================================&#10;&#10;1. Ground Truth: DSSP and STRIDE are considered ground truth reference methods&#10;   for burial classification and secondary structure.&#10;&#10;2. Missing Values: Empty cells indicate data unavailable (e.g., if DSSP/STRIDE&#10;   could not process that residue or calculation failed).&#10;&#10;3. Classification Thresholds:&#10;   - Interior (buried): Low ASA, high neighbor count, high uniformity&#10;   - Exterior (exposed): High ASA, low neighbor count, low uniformity&#10;&#10;4. Usage: These files are used for:&#10;   - Decision tree classification (decision_tree_zscore_analysis.py)&#10;   - Cross-validation analysis (cross_validation_analysis.py)&#10;   - Performance comparison against reference methods&#10;   - Feature importance analysis&#10;&#10;5. File Generation:&#10;   - Run: python protein_burial_analysis.py&#10;   - Or: python extract_ca.py [pdb_file]&#10;&#10;================================================================================&#10;EXAMPLE ROW&#10;================================================================================&#10;&#10;res_id,res_num,dssp_asa,dssp_class,stride_asa,stride_class,ncps_sphere_6,...&#10;LEU,11,0.0,0,0.0,0,8,0.667,27,0.828,0,H,H&#10;&#10;Interpretation:&#10;- Leucine at position 11&#10;- DSSP ASA = 0.0 (completely buried)&#10;- DSSP class = 0 (interior)&#10;- STRIDE ASA = 0.0 (completely buried)&#10;- STRIDE class = 0 (interior)&#10;- 8 neighbors within 6Å (densely packed)&#10;- Uniformity 6Å = 0.667 (uniform distribution)&#10;- 27 neighbors within 10Å (very densely packed)&#10;- Uniformity 10Å = 0.828 (highly uniform)&#10;- Predicted class = 0 (interior) - correct!&#10;- Both DSSP and STRIDE assign alpha helix (H)&#10;&#10;This residue is clearly buried in the protein core.&#10;&#10;================================================================================&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/DSSP_STRIDE_AGNOSTIC_APPROACH.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/DSSP_STRIDE_AGNOSTIC_APPROACH.md" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="# DSSP/STRIDE AGNOSTIC APPROACH - IMPLEMENTATION SUMMARY&#10;&#10;**Date:** November 11, 2025  &#10;**Status:** ✅ IMPLEMENTED AND VERIFIED&#10;&#10;---&#10;&#10;## ⚠️ CRITICAL PRINCIPLE&#10;&#10;**DSSP and STRIDE outputs are used ONLY for validation and comparison.**  &#10;**They are NOT used as input features for any classification models.**&#10;&#10;This ensures our method is completely **independent** of existing protein analysis tools and can be evaluated objectively against them as ground truth references.&#10;&#10;---&#10;&#10;## WHAT WE USE FOR CLASSIFICATION&#10;&#10;### ✅ Allowed Features (Neighbor-Based Only):&#10;&#10;1. **`ncps_sphere_6`** - Neighbor count within 6Å radius&#10;2. **`ncps_sphere_10`** - Neighbor count within 10Å radius  &#10;3. **`ncps_sphere_6_uni`** - Spatial uniformity at 6Å radius&#10;4. **`ncps_sphere_10_uni`** - Spatial uniformity at 10Å radius&#10;&#10;**All features are z-score normalized per protein before model training.**&#10;&#10;### ❌ NOT Used for Classification:&#10;&#10;- `dssp_asa` - DSSP accessible surface area&#10;- `dssp_class` - DSSP classification (used as ground truth label for training)&#10;- `stride_asa` - STRIDE accessible surface area (NOT used at all in models)&#10;- `stride_class` - STRIDE classification (used only for validation)&#10;- `dssp_ss` - DSSP secondary structure (validation only)&#10;- `stride_ss` - STRIDE secondary structure (validation only)&#10;&#10;---&#10;&#10;## CHANGES MADE TO ENSURE AGNOSTIC APPROACH&#10;&#10;### Files Modified:&#10;&#10;1. **`decision_tree_zscore_analysis.py`**&#10;   - ❌ REMOVED: `stride_asa` from feature normalization&#10;   - ✅ NOW USES: Only 4 neighbor-based features&#10;   - Before: 5 features (including stride_asa_norm)&#10;   - After: 4 features (neighbor counts + uniformity only)&#10;&#10;2. **`cross_validation_analysis.py`**&#10;   - ❌ REMOVED: `stride_asa_norm` from all three model variants&#10;   - ✅ NOW USES: Only neighbor-based features for cross-validation&#10;&#10;3. **`create_enhanced_tree_viz.py`**&#10;   - ❌ REMOVED: `stride_asa_norm` from visualization features&#10;   - ✅ NOW USES: Only neighbor-based features for tree visualization&#10;&#10;4. **`CSV_HEADER_DESCRIPTION.txt`**&#10;   - ✅ ADDED: Clear warning that DSSP/STRIDE are for validation only&#10;   - ✅ ADDED: Explicit list of which features are used in models&#10;&#10;---&#10;&#10;## MODEL PERFORMANCE RESULTS (DSSP/STRIDE AGNOSTIC)&#10;&#10;### Model 1: All Features (6Å + 10Å)&#10;**Features:** 4 features (NC6, NC10, Uni6, Uni10)&#10;&#10;**Training Performance:**&#10;- Accuracy: 89.60%&#10;- Precision: 90% (weighted)&#10;- Recall: 90% (weighted)&#10;&#10;**Cross-Validation (5-fold):**&#10;- Validation Accuracy: **87.56% ± 0.90%**&#10;- Overfitting Gap: 2.13% ✅ Excellent generalization&#10;- Per-fold consistency: 86.4% - 88.7%&#10;&#10;**Feature Importance:**&#10;- ncps_sphere_10_uni_norm: **90.25%** (most important!)&#10;- ncps_sphere_10_norm: 3.77%&#10;- ncps_sphere_6_uni_norm: 4.17%&#10;- ncps_sphere_6_norm: 1.81%&#10;&#10;### Model 2: 10Å Features Only&#10;**Features:** 2 features (NC10, Uni10)&#10;&#10;**Training Performance:**&#10;- Accuracy: 88.65%&#10;- Precision: 89% (weighted)&#10;- Recall: 89% (weighted)&#10;&#10;**Cross-Validation (5-fold):**&#10;- Validation Accuracy: **85.66% ± 1.65%**&#10;- Overfitting Gap: 3.14% ✅ Good generalization&#10;- Per-fold consistency: 83.7% - 87.7%&#10;&#10;**Feature Importance:**&#10;- ncps_sphere_10_uni_norm: **94.99%** (dominant!)&#10;- ncps_sphere_10_norm: 5.01%&#10;&#10;### Model 3: 6Å Features Only&#10;**Features:** 2 features (NC6, Uni6)&#10;&#10;**Training Performance:**&#10;- Accuracy: 73.40%&#10;- Precision: 73% (weighted)&#10;- Recall: 73% (weighted)&#10;&#10;**Cross-Validation (5-fold):**&#10;- Validation Accuracy: **69.53% ± 1.87%**&#10;- Lower performance (expected - shorter radius less informative)&#10;&#10;---&#10;&#10;## KEY INSIGHTS&#10;&#10;### 1. **10Å Uniformity is the Most Predictive Feature**&#10;The `ncps_sphere_10_uni` (uniformity at 10Å radius) accounts for **90-95%** of feature importance across all models. This suggests that:&#10;- Interior residues have highly uniform neighbor distribution (spherical packing)&#10;- Exterior residues have non-uniform distribution (hemispherical or surface-biased)&#10;&#10;### 2. **10Å Features Outperform 6Å Features**&#10;- 10Å model: 85.7% cross-validation accuracy&#10;- 6Å model: 69.5% cross-validation accuracy&#10;- Reason: Larger radius captures more structural context&#10;&#10;### 3. **No Dependence on DSSP/STRIDE**&#10;Our models achieve **87.6% accuracy** using ONLY geometric neighbor features, without any reference to:&#10;- Accessible surface area calculations&#10;- Secondary structure assignments&#10;- Solvent accessibility computations&#10;&#10;### 4. **Excellent Generalization**&#10;All models show small overfitting gaps (2-3%), indicating robust performance on unseen data.&#10;&#10;---&#10;&#10;## CSV FILE STRUCTURE&#10;&#10;### Columns for Model Training (4 features):&#10;```&#10;ncps_sphere_6          → ncps_sphere_6_norm (z-score)&#10;ncps_sphere_10         → ncps_sphere_10_norm (z-score)&#10;ncps_sphere_6_uni      → ncps_sphere_6_uni_norm (z-score)&#10;ncps_sphere_10_uni     → ncps_sphere_10_uni_norm (z-score)&#10;```&#10;&#10;### Columns for Validation Only:&#10;```&#10;dssp_asa              → Ground truth reference&#10;dssp_class            → Training labels (0=interior, 1=exterior)&#10;dssp_ss               → Secondary structure validation&#10;stride_asa            → Alternative ground truth&#10;stride_class          → Validation against STRIDE&#10;stride_ss             → Secondary structure validation&#10;```&#10;&#10;---&#10;&#10;## HOW TO VERIFY AGNOSTIC APPROACH&#10;&#10;### Check Feature Lists:&#10;```bash&#10;# Should NOT contain 'stride_asa' or 'dssp_asa'&#10;grep &quot;feature_cols = &quot; decision_tree_zscore_analysis.py&#10;```&#10;&#10;Expected output:&#10;```python&#10;feature_cols = ['ncps_sphere_6_norm', 'ncps_sphere_10_norm',&#10;                'ncps_sphere_6_uni_norm', 'ncps_sphere_10_uni_norm']&#10;```&#10;&#10;### Check Normalized Data:&#10;```python&#10;import pandas as pd&#10;df = pd.read_csv('results/decision_tree/combined_normalized.csv')&#10;&#10;# Features used in models&#10;model_features = ['ncps_sphere_6_norm', 'ncps_sphere_10_norm', &#10;                  'ncps_sphere_6_uni_norm', 'ncps_sphere_10_uni_norm']&#10;&#10;# Validation only (not used in models)&#10;validation_cols = ['dssp_asa', 'dssp_class', 'stride_asa', 'stride_class']&#10;```&#10;&#10;---&#10;&#10;## COMPARISON: Before vs After&#10;&#10;### Before (INCORRECT):&#10;```python&#10;features = ['stride_asa', 'ncps_sphere_6', 'ncps_sphere_10',&#10;            'ncps_sphere_6_uni', 'ncps_sphere_10_uni']  # 5 features&#10;# ❌ Using STRIDE ASA - NOT agnostic!&#10;```&#10;&#10;### After (CORRECT):&#10;```python&#10;features = ['ncps_sphere_6', 'ncps_sphere_10',&#10;            'ncps_sphere_6_uni', 'ncps_sphere_10_uni']  # 4 features&#10;# ✅ Only neighbor-based features - Fully agnostic!&#10;```&#10;&#10;---&#10;&#10;## VALIDATION APPROACH&#10;&#10;### How We Use DSSP/STRIDE:&#10;&#10;1. **Training Labels**: Use `dssp_class` as ground truth for supervised learning&#10;2. **Validation Metrics**: Compare predictions against both DSSP and STRIDE&#10;3. **Performance Comparison**: Report agreement with both methods&#10;4. **Confusion Matrices**: Show where our method agrees/disagrees with references&#10;&#10;### We DO NOT:&#10;- Use DSSP/STRIDE ASA values as input features&#10;- Use DSSP/STRIDE secondary structure in classification&#10;- Depend on DSSP/STRIDE calculations in any way during prediction&#10;&#10;---&#10;&#10;## CONFUSION MATRIX INTERPRETATION&#10;&#10;### ⚠️ CRITICAL: Understanding Ground Truth&#10;&#10;**When validating ACCORDING TO DSSP:**&#10;- **Ground Truth = DSSP classifications**&#10;- True Positive (TP): DSSP=Exterior (1) AND NCPS=Exterior (1) ✓&#10;- True Negative (TN): DSSP=Interior (0) AND NCPS=Interior (0) ✓&#10;- False Positive (FP): DSSP=Interior (0) BUT NCPS=Exterior (1) ✗&#10;- False Negative (FN): DSSP=Exterior (1) BUT NCPS=Interior (0) ✗&#10;&#10;**When validating ACCORDING TO STRIDE:**&#10;- **Ground Truth = STRIDE classifications**&#10;- True Positive (TP): STRIDE=Exterior (1) AND NCPS=Exterior (1) ✓&#10;- True Negative (TN): STRIDE=Interior (0) AND NCPS=Interior (0) ✓&#10;- False Positive (FP): STRIDE=Interior (0) BUT NCPS=Exterior (1) ✗&#10;- False Negative (FN): STRIDE=Exterior (1) BUT NCPS=Interior (0) ✗&#10;&#10;### Example from 7UPO Protein:&#10;&#10;**According to DSSP:**&#10;```&#10;                      Predicted Interior (0)  Predicted Exterior (1)&#10;True Interior (0)               105 (TN)              10 (FP)&#10;True Exterior (1)                28 (FN)              85 (TP)&#10;```&#10;&#10;- TN=105: Both DSSP and NCPS agree residue is Interior&#10;- TP=85: Both DSSP and NCPS agree residue is Exterior  &#10;- FP=10: DSSP says Interior, but NCPS wrongly predicts Exterior&#10;- FN=28: DSSP says Exterior, but NCPS wrongly predicts Interior&#10;&#10;**Accuracy = (TN + TP) / Total = (105 + 85) / 228 = 83.33%**&#10;&#10;---&#10;&#10;## FILES TO RUN&#10;&#10;To regenerate all results with the agnostic approach:&#10;&#10;```bash&#10;# 1. Generate decision trees (DSSP/STRIDE agnostic)&#10;python decision_tree_zscore_analysis.py&#10;&#10;# 2. Run cross-validation analysis&#10;python cross_validation_analysis.py&#10;&#10;# 3. Generate detailed reports (shows validation against DSSP/STRIDE)&#10;python generate_detailed_reports.py&#10;&#10;# 4. Create visualizations&#10;python create_enhanced_tree_viz.py&#10;```&#10;&#10;---&#10;&#10;## THEORETICAL JUSTIFICATION&#10;&#10;### Why This Approach is Valid:&#10;&#10;1. **Pure Geometry**: Neighbor counts and uniformity are purely geometric properties derived from CA atom coordinates&#10;2. **No External Tools**: No dependence on DSSP, STRIDE, or any other external analysis tool&#10;3. **Physical Principle**: Interior residues are surrounded uniformly; surface residues are not&#10;4. **Reproducible**: Given only PDB coordinates, anyone can compute these features&#10;5. **Interpretable**: Easy to understand and visualize (unlike black-box methods)&#10;&#10;### Why DSSP/STRIDE are Still Useful:&#10;&#10;1. **Ground Truth**: Provide established classification labels for training&#10;2. **Validation**: Allow comparison with widely-accepted methods&#10;3. **Benchmarking**: Industry standard for performance evaluation&#10;4. **Context**: Help understand where/why our method agrees or disagrees&#10;&#10;---&#10;&#10;## CONCLUSION&#10;&#10;✅ **Implementation Complete**: All models now use ONLY neighbor-based features  &#10;✅ **Performance Maintained**: 87.6% accuracy without DSSP/STRIDE features  &#10;✅ **Fully Independent**: Can classify burial status from coordinates alone  &#10;✅ **Properly Validated**: DSSP/STRIDE used appropriately for comparison only  &#10;&#10;**The method is now completely DSSP and STRIDE agnostic!** &#10;&#10;---&#10;&#10;## CONTACT &amp; QUESTIONS&#10;&#10;For questions about this implementation, refer to:&#10;- `CSV_HEADER_DESCRIPTION.txt` - Details on which columns are used where&#10;- `decision_tree_zscore_analysis.py` - Main classification code&#10;- `results/[protein]_detailed_report.txt` - Performance against DSSP/STRIDE&#10;&#10;**Last Updated:** November 11, 2025&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/MARKO_QUESTIONS_ANSWERED.txt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/MARKO_QUESTIONS_ANSWERED.txt" />
              <option name="updatedContent" value="================================================================================&#10;ANSWERS TO MARKO'S QUESTIONS - SUMMARY&#10;================================================================================&#10;Date: November 11, 2025&#10;Project: Protein Burial Classification Analysis&#10;================================================================================&#10;&#10;This document provides direct answers to your specific questions from our &#10;conversation, with file locations and verification steps.&#10;&#10;================================================================================&#10;QUESTION 1: WHERE CAN I FIND REGRESSION TREE IMPLEMENTATION?&#10;================================================================================&#10;&#10;ANSWER: There is NO regression tree implementation in this project.&#10;&#10;DETAILS:&#10;- Your project only contains CLASSIFICATION trees (DecisionTreeClassifier)&#10;- NO regression trees (DecisionTreeRegressor) exist anywhere&#10;- All decision trees classify residues as Interior (0) or Exterior (1)&#10;- This is appropriate since burial classification is a binary problem&#10;&#10;FILES WITH DECISION TREE CLASSIFIERS:&#10;- decision_tree_zscore_analysis.py&#10;- cross_validation_analysis.py&#10;- verify_decision_tree.py&#10;- create_enhanced_tree_viz.py&#10;- create_intuitive_tree_viz.py&#10;- compare_split_strategies.py&#10;&#10;================================================================================&#10;QUESTION 2: WHERE IS THE Z-SCORE IMPLEMENTATION?&#10;================================================================================&#10;&#10;ANSWER: Z-score normalization is in decision_tree_zscore_analysis.py&#10;&#10;LOCATION: Lines 49-57 of decision_tree_zscore_analysis.py&#10;&#10;CODE:&#10;```python&#10;# Z-score normalization per protein&#10;for feat in features:&#10;    if df[feat].notna().sum() &gt; 0:&#10;        mean = df[feat].mean()&#10;        std = df[feat].std()&#10;        if std &gt; 0:&#10;            df[f'{feat}_norm'] = (df[feat] - mean) / std&#10;```&#10;&#10;FORMULA: z = (value - mean) / std&#10;&#10;This normalizes each protein SEPARATELY before combining them, accounting for&#10;size differences between proteins.&#10;&#10;FILE RENAMED: &#10;- OLD: decision_tree_analysis.py&#10;- NEW: decision_tree_zscore_analysis.py (renamed to include &quot;zscore&quot; in name)&#10;&#10;================================================================================&#10;QUESTION 3: WHERE IS THE CROSS-VALIDATION IMPLEMENTATION?&#10;================================================================================&#10;&#10;ANSWER: Cross-validation is in cross_validation_analysis.py&#10;&#10;LOCATION: /Users/famnit/Desktop/pythonProject/cross_validation_analysis.py&#10;&#10;KEY DETAILS:&#10;- Uses K-Fold cross-validation (k=5 folds)&#10;- Line 57: KFold(n_splits=5, shuffle=True, random_state=42)&#10;- Evaluates 3 models: All features, 6Å only, 10Å only&#10;- Reports: Accuracy, Precision, Recall, F1-score&#10;- Checks for overfitting (train vs validation accuracy)&#10;&#10;OUTPUT FILES:&#10;- results/decision_tree/cross_validation_report.txt&#10;- results/decision_tree/cross_validation_comparison.png&#10;&#10;HOW TO RUN:&#10;python cross_validation_analysis.py&#10;&#10;IMPORTANT: Cross-validation uses PRE-NORMALIZED data from &#10;combined_normalized.csv (each protein normalized separately, then combined)&#10;&#10;================================================================================&#10;QUESTION 4: ARE ALL 4 PROTEINS USED TOGETHER IN DECISION TREE?&#10;================================================================================&#10;&#10;ANSWER: YES, all 4 proteins are used together.&#10;&#10;STRATEGY (from decision_tree_zscore_analysis.py lines 230-247):&#10;1. Load each protein separately (3PTE, 4d05, 6wti, 7upo)&#10;2. Normalize EACH protein individually using z-score&#10;3. Concatenate all normalized proteins together&#10;4. Train a SINGLE decision tree on the combined dataset&#10;&#10;PROTEINS INCLUDED:&#10;- 3PTE: 347 residues&#10;- 4d05: 493 residues&#10;- 6wti: 1207 residues&#10;- 7upo: 228 residues&#10;- TOTAL: 2275 residues combined&#10;&#10;WHY THIS APPROACH:&#10;- Accounts for size differences between proteins&#10;- Creates larger, more diverse training dataset&#10;- Model learns general patterns across different proteins&#10;- Z-score normalization ensures fair comparison&#10;&#10;================================================================================&#10;QUESTION 5: CSV FILE OUTPUT AND HEADER DESCRIPTIONS&#10;================================================================================&#10;&#10;ANSWER: CSV files are in results/ folder with header descriptions documented&#10;&#10;EXAMPLE CSV OUTPUT FILE:&#10;- Location: /Users/famnit/Desktop/pythonProject/3pte_sample_output.csv&#10;- Full files: results/3pte_results.csv (and 4d05, 6wti, 7upo)&#10;&#10;HEADER DESCRIPTION FILE (NEW):&#10;- Location: /Users/famnit/Desktop/pythonProject/CSV_HEADER_DESCRIPTION.txt&#10;- Contains: Detailed explanation of all 13 columns&#10;- Includes: Data types, ranges, units, and interpretation&#10;&#10;CSV COLUMNS (13 total):&#10;1. res_id - Amino acid type (ALA, LEU, etc.)&#10;2. res_num - Position in sequence&#10;3. dssp_asa - DSSP accessible surface area&#10;4. dssp_class - DSSP classification (0=interior, 1=exterior)&#10;5. stride_asa - STRIDE accessible surface area&#10;6. stride_class - STRIDE classification (0=interior, 1=exterior)&#10;7. ncps_sphere_6 - Neighbor count at 6Å&#10;8. ncps_sphere_6_uni - Uniformity at 6Å&#10;9. ncps_sphere_10 - Neighbor count at 10Å&#10;10. ncps_sphere_10_uni - Uniformity at 10Å&#10;11. ncps_class - Your algorithm's prediction&#10;12. dssp_ss - DSSP secondary structure&#10;13. stride_ss - STRIDE secondary structure&#10;&#10;NORMALIZED CSV (for machine learning):&#10;- Location: results/decision_tree/combined_normalized.csv&#10;- Additional columns: *_norm (z-score normalized values)&#10;- Protein identifier column added&#10;&#10;================================================================================&#10;QUESTION 6: ENHANCED DETAILED REPORTS WITH CONFUSION MATRICES&#10;================================================================================&#10;&#10;ANSWER: Enhanced reports generated with ALL requested information&#10;&#10;LOCATION: results/[protein]_detailed_report.txt&#10;- results/3PTE_detailed_report.txt&#10;- results/4d05_detailed_report.txt&#10;- results/6wti_detailed_report.txt&#10;- results/7upo_detailed_report.txt&#10;&#10;NEW SECTIONS ADDED:&#10;&#10;1. SUMMARY STATISTICS (Enhanced):&#10;   ✓ DSSP Classification with counts&#10;   ✓ DSSP Cutoff Value: ASA ≥ 25%&#10;   ✓ STRIDE Classification with counts (NEW)&#10;   ✓ STRIDE Cutoff Value: ASA ≥ 20% (NEW)&#10;   ✓ NCPS Classification&#10;   ✓ Agreement with DSSP percentage&#10;   ✓ Agreement with STRIDE percentage (NEW)&#10;&#10;2. COMPLETE STATISTICS SECTION (NEW):&#10;   ✓ ACCORDING TO DSSP (Ground Truth = DSSP)&#10;     - Complete confusion matrix with TN, FP, FN, TP&#10;     - Confusion matrix interpretation&#10;     - Overall accuracy, precision, recall, F1-score&#10;     - Per-class metrics (Interior and Exterior separately)&#10;   &#10;   ✓ ACCORDING TO STRIDE (Ground Truth = STRIDE)&#10;     - Complete confusion matrix with TN, FP, FN, TP&#10;     - Confusion matrix interpretation&#10;     - Overall accuracy, precision, recall, F1-score&#10;     - Per-class metrics (Interior and Exterior separately)&#10;&#10;3. AGREEMENT/DISAGREEMENT LISTS (NEW):&#10;   ✓ Residues in agreement: NCPS-DSSP (with all metrics)&#10;   ✓ Residues in disagreement: NCPS-DSSP (with all metrics)&#10;   ✓ Residues in agreement: NCPS-STRIDE (with all metrics)&#10;   ✓ Residues in disagreement: NCPS-STRIDE (with all metrics)&#10;&#10;EXAMPLE FROM 7UPO:&#10;According to DSSP:&#10;- TN=105, FP=10, FN=28, TP=85&#10;- Accuracy: 83.33% (190/228)&#10;- 190 residues agree, 38 disagree&#10;&#10;According to STRIDE:&#10;- TN=72, FP=18, FN=61, TP=70&#10;- Accuracy: 64.25% (142/221)&#10;- 142 residues agree, 79 disagree&#10;&#10;HOW TO REGENERATE:&#10;python generate_detailed_reports.py&#10;&#10;================================================================================&#10;QUESTION 7 (P.S.): CONFUSION MATRIX GROUND TRUTH INTERPRETATION&#10;================================================================================&#10;&#10;ANSWER: YES, you are 100% CORRECT!&#10;&#10;ACCORDING TO DSSP (Ground Truth = DSSP classifications):&#10;- True Positive (TP): DSSP=Exterior (1) AND NCPS=Exterior (1) ✓&#10;- True Negative (TN): DSSP=Interior (0) AND NCPS=Interior (0) ✓&#10;- False Positive (FP): DSSP=Interior (0) BUT NCPS=Exterior (1) ✗&#10;- False Negative (FN): DSSP=Exterior (1) BUT NCPS=Interior (0) ✗&#10;&#10;ACCORDING TO STRIDE (Ground Truth = STRIDE classifications):&#10;- True Positive (TP): STRIDE=Exterior (1) AND NCPS=Exterior (1) ✓&#10;- True Negative (TN): STRIDE=Interior (0) AND NCPS=Interior (0) ✓&#10;- False Positive (FP): STRIDE=Interior (0) BUT NCPS=Exterior (1) ✗&#10;- False Negative (FN): STRIDE=Exterior (1) BUT NCPS=Interior (0) ✗&#10;&#10;KEY PRINCIPLE:&#10;The reference method (DSSP or STRIDE) defines what is &quot;TRUE&quot;&#10;Your predictions (NCPS) define what is &quot;PREDICTED&quot;&#10;&#10;CONFUSION MATRIX FORMAT:&#10;                      Predicted Interior (0)  Predicted Exterior (1)&#10;True Interior (0)               TN                      FP&#10;True Exterior (1)               FN                      TP&#10;&#10;This is correctly implemented in all detailed reports!&#10;&#10;VERIFICATION:&#10;See any detailed report file, section &quot;STATISTICS&quot;, starting around line 302&#10;Example: results/7upo_detailed_report.txt&#10;&#10;================================================================================&#10;QUESTION 8 (THEORY ADDON): DSSP/STRIDE AGNOSTIC APPROACH&#10;================================================================================&#10;&#10;ANSWER: YES, fully implemented! DSSP/STRIDE are used ONLY for validation.&#10;&#10;CRITICAL PRINCIPLE:&#10;⚠️ DSSP and STRIDE outputs are used ONLY for validation and comparison.&#10;⚠️ They are NOT used as input features for any classification models.&#10;&#10;FEATURES USED FOR CLASSIFICATION (Neighbor-Based ONLY):&#10;✓ ncps_sphere_6_norm - Neighbor count at 6Å (z-score)&#10;✓ ncps_sphere_10_norm - Neighbor count at 10Å (z-score)&#10;✓ ncps_sphere_6_uni_norm - Uniformity at 6Å (z-score)&#10;✓ ncps_sphere_10_uni_norm - Uniformity at 10Å (z-score)&#10;&#10;TOTAL: 4 features (all YOUR neighbor-based features)&#10;&#10;NOT USED FOR CLASSIFICATION:&#10;✗ stride_asa - REMOVED from all models&#10;✗ dssp_asa - Never used in models&#10;✓ dssp_class - Used ONLY as training labels (ground truth)&#10;✓ stride_class - Used ONLY for validation comparison&#10;&#10;CHANGES MADE:&#10;1. decision_tree_zscore_analysis.py&#10;   - BEFORE: 5 features (including stride_asa_norm)&#10;   - AFTER: 4 features (neighbor-based only)&#10;&#10;2. cross_validation_analysis.py&#10;   - REMOVED: stride_asa_norm from all 3 model variants&#10;&#10;3. create_enhanced_tree_viz.py&#10;   - REMOVED: stride_asa_norm from visualizations&#10;&#10;4. CSV_HEADER_DESCRIPTION.txt&#10;   - ADDED: Warning that DSSP/STRIDE are validation-only&#10;&#10;PERFORMANCE WITH AGNOSTIC APPROACH:&#10;- All features (4): 87.56% ± 0.90% cross-validation accuracy&#10;- 10Å only (2): 85.66% ± 1.65% cross-validation accuracy&#10;- 6Å only (2): 69.53% ± 1.87% cross-validation accuracy&#10;&#10;MOST IMPORTANT FEATURE:&#10;ncps_sphere_10_uni_norm: 90-95% feature importance&#10;(This is YOUR uniformity metric at 10Å!)&#10;&#10;VERIFICATION:&#10;grep &quot;feature_cols = &quot; decision_tree_zscore_analysis.py&#10;&#10;Should show ONLY:&#10;['ncps_sphere_6_norm', 'ncps_sphere_10_norm',&#10; 'ncps_sphere_6_uni_norm', 'ncps_sphere_10_uni_norm']&#10;&#10;FULL DOCUMENTATION:&#10;- File: DSSP_STRIDE_AGNOSTIC_APPROACH.md&#10;- Contains: Complete explanation, before/after comparison, verification steps&#10;&#10;================================================================================&#10;SUMMARY OF FILE LOCATIONS&#10;================================================================================&#10;&#10;DOCUMENTATION FILES (Created for you):&#10;1. CSV_HEADER_DESCRIPTION.txt - Explains all CSV columns&#10;2. DSSP_STRIDE_AGNOSTIC_APPROACH.md - Complete agnostic approach explanation&#10;3. MARKO_QUESTIONS_ANSWERED.txt - This file (direct answers)&#10;4. 3pte_sample_output.csv - Sample CSV output (30 rows)&#10;&#10;MAIN ANALYSIS SCRIPTS:&#10;1. decision_tree_zscore_analysis.py - Main decision tree with z-score (RENAMED)&#10;2. cross_validation_analysis.py - K-fold cross-validation&#10;3. generate_detailed_reports.py - Creates enhanced reports with confusion matrices&#10;4. extract_ca.py - Original extraction and classification code&#10;&#10;OUTPUT FILES:&#10;1. results/[protein]_results.csv - Individual protein results (4 files)&#10;2. results/[protein]_detailed_report.txt - Enhanced reports (4 files)&#10;3. results/decision_tree/combined_normalized.csv - All proteins normalized&#10;4. results/decision_tree/cross_validation_report.txt - CV results&#10;5. results/decision_tree/decision_tree_summary.txt - Training accuracies&#10;6. results/decision_tree/*.png - Visualizations&#10;&#10;================================================================================&#10;HOW TO REGENERATE EVERYTHING&#10;================================================================================&#10;&#10;# Step 1: Generate decision trees (DSSP/STRIDE agnostic, 4 features only)&#10;python decision_tree_zscore_analysis.py&#10;&#10;# Step 2: Run cross-validation (validates generalization)&#10;python cross_validation_analysis.py&#10;&#10;# Step 3: Generate enhanced detailed reports (with confusion matrices)&#10;python generate_detailed_reports.py&#10;&#10;# Step 4: Create visualizations&#10;python create_enhanced_tree_viz.py&#10;&#10;================================================================================&#10;KEY FINDINGS&#10;================================================================================&#10;&#10;1. Z-SCORE NORMALIZATION:&#10;   - Applied per protein before combining&#10;   - Formula: (value - mean) / std&#10;   - Accounts for protein size differences&#10;&#10;2. ALL 4 PROTEINS COMBINED:&#10;   - 3PTE (347) + 4d05 (493) + 6wti (1207) + 7upo (228) = 2275 residues&#10;   - Each normalized separately, then concatenated&#10;   - Single model trained on combined dataset&#10;&#10;3. DSSP/STRIDE AGNOSTIC:&#10;   - ONLY 4 neighbor-based features used&#10;   - stride_asa REMOVED from all models&#10;   - 87.6% accuracy without any DSSP/STRIDE features!&#10;&#10;4. MOST IMPORTANT FEATURE:&#10;   - ncps_sphere_10_uni (YOUR uniformity at 10Å)&#10;   - Accounts for 90-95% of feature importance&#10;   - Interior: uniform spherical packing&#10;   - Exterior: non-uniform hemispherical distribution&#10;&#10;5. CONFUSION MATRIX INTERPRETATION:&#10;   - DSSP defines ground truth when validating against DSSP&#10;   - STRIDE defines ground truth when validating against STRIDE&#10;   - TN/TP = Agreement, FP/FN = Disagreement&#10;   - Correctly implemented in all reports&#10;&#10;6. CROSS-VALIDATION RESULTS:&#10;   - 5-fold CV with shuffling&#10;   - Uses pre-normalized data (combined_normalized.csv)&#10;   - Excellent generalization (2-3% overfitting gap)&#10;   - Consistent across folds (86-88% accuracy range)&#10;&#10;7. NO REGRESSION TREES:&#10;   - Only classification trees exist&#10;   - Appropriate for binary problem (interior vs exterior)&#10;   - No DecisionTreeRegressor anywhere in project&#10;&#10;================================================================================&#10;QUESTIONS ANSWERED: ✓ ALL COMPLETE&#10;================================================================================&#10;&#10;✓ Q1: Regression tree location → NO regression trees (classification only)&#10;✓ Q2: Z-score location → decision_tree_zscore_analysis.py lines 49-57&#10;✓ Q3: Cross-validation location → cross_validation_analysis.py&#10;✓ Q4: All proteins together? → YES, normalized separately then combined&#10;✓ Q5: CSV output &amp; headers → Sample + CSV_HEADER_DESCRIPTION.txt created&#10;✓ Q6: Enhanced reports → All 4 proteins with complete confusion matrices&#10;✓ Q7 (p.s.): Confusion matrix → YES, DSSP/STRIDE are ground truth correctly&#10;✓ Q8 (theory): DSSP/STRIDE agnostic → YES, fully implemented (4 features only)&#10;&#10;================================================================================&#10;END OF SUMMARY&#10;================================================================================&#10;&#10;For detailed explanations, see:&#10;- DSSP_STRIDE_AGNOSTIC_APPROACH.md (theory and implementation)&#10;- CSV_HEADER_DESCRIPTION.txt (column descriptions)&#10;- results/[protein]_detailed_report.txt (performance metrics)&#10;&#10;Last Updated: November 11, 2025&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/clean_csv_nulls.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/clean_csv_nulls.py" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Replace NULL/NaN values in CSV files with 0.000000&#10;Preserves formatting and ensures no empty cells&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;&#10;def clean_csv_file(csv_path):&#10;    &quot;&quot;&quot;Replace all NaN/null values with 0.000000 in CSV file.&quot;&quot;&quot;&#10;    print(f&quot;\nProcessing: {csv_path}&quot;)&#10;    &#10;    # Read CSV&#10;    df = pd.read_csv(csv_path)&#10;    &#10;    # Count nulls before&#10;    null_count_before = df.isnull().sum().sum()&#10;    print(f&quot;  Null values before: {null_count_before}&quot;)&#10;    &#10;    # Replace NaN with 0.0 for numeric columns&#10;    for col in df.columns:&#10;        if df[col].dtype in ['float64', 'int64']:&#10;            df[col] = df[col].fillna(0.0)&#10;        elif df[col].dtype == 'object':&#10;            # For string columns, replace NaN with '-' or empty string&#10;            df[col] = df[col].fillna('-')&#10;    &#10;    # Count nulls after&#10;    null_count_after = df.isnull().sum().sum()&#10;    print(f&quot;  Null values after: {null_count_after}&quot;)&#10;    &#10;    # Save back to CSV with proper formatting&#10;    # Use float_format to ensure consistent decimal places&#10;    df.to_csv(csv_path, index=False, float_format='%.10f')&#10;    print(f&quot;  ✅ Saved: {csv_path}&quot;)&#10;    &#10;    return null_count_before, null_count_after&#10;&#10;def main():&#10;    &quot;&quot;&quot;Clean all CSV result files.&quot;&quot;&quot;&#10;    print(&quot;=&quot;*80)&#10;    print(&quot;CLEANING CSV FILES - REPLACING NULL VALUES WITH 0.000000&quot;)&#10;    print(&quot;=&quot;*80)&#10;    &#10;    # List of CSV files to clean&#10;    csv_files = [&#10;        'results/3pte_results.csv',&#10;        'results/4d05_results.csv',&#10;        'results/6wti_results.csv',&#10;        'results/7upo_results.csv',&#10;        'results/combined_results.csv',&#10;        'results/decision_tree/combined_normalized.csv'&#10;    ]&#10;    &#10;    total_before = 0&#10;    total_after = 0&#10;    &#10;    for csv_file in csv_files:&#10;        csv_path = Path(csv_file)&#10;        if csv_path.exists():&#10;            before, after = clean_csv_file(csv_path)&#10;            total_before += before&#10;            total_after += after&#10;        else:&#10;            print(f&quot;\n⚠️  File not found: {csv_file}&quot;)&#10;    &#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(f&quot;COMPLETE!&quot;)&#10;    print(f&quot;Total null values replaced: {total_before}&quot;)&#10;    print(f&quot;Remaining null values: {total_after}&quot;)&#10;    print(&quot;=&quot;*80)&#10;    &#10;    # Show example of cleaned data&#10;    print(&quot;\nExample from 3pte_results.csv (first 5 rows):&quot;)&#10;    df_sample = pd.read_csv('results/3pte_results.csv')&#10;    print(df_sample.head(5).to_string())&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/create_enhanced_tree_viz.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/create_enhanced_tree_viz.py" />
              <option name="originalContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Enhanced Decision Tree Visualization&#10;Creates beautiful, publication-quality decision tree diagrams&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;import matplotlib.pyplot as plt&#10;import matplotlib.patches as mpatches&#10;from sklearn.tree import DecisionTreeClassifier, plot_tree&#10;from sklearn.metrics import accuracy_score&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;def load_normalized_data():&#10;    &quot;&quot;&quot;Load the pre-normalized combined dataset.&quot;&quot;&quot;&#10;    data_file = Path('results/decision_tree/combined_normalized.csv')&#10;    if not data_file.exists():&#10;        print(&quot;❌ Error: Run decision_tree_analysis.py first to generate normalized data&quot;)&#10;        return None&#10;    df = pd.read_csv(data_file)&#10;    print(f&quot;✅ Loaded normalized data: {len(df)} residues&quot;)&#10;    return df&#10;&#10;def create_enhanced_tree_visualization(clf, feature_names, model_name, accuracy, output_file):&#10;    &quot;&quot;&quot;&#10;    Create a beautiful, enhanced decision tree visualization with custom styling.&#10;    &quot;&quot;&quot;&#10;    # Set up the figure with high quality&#10;    plt.figure(figsize=(24, 14), dpi=150, facecolor='white')&#10;&#10;    # Custom color scheme - gradient from interior (blue) to exterior (orange)&#10;    colors = ['#3498db', '#e74c3c']  # Blue for interior, Red for exterior&#10;&#10;    # Plot the tree with enhanced styling&#10;    plot_tree(clf,&#10;              feature_names=feature_names,&#10;              class_names=['Interior (0)', 'Exterior (1)'],&#10;              filled=True,&#10;              rounded=True,&#10;              fontsize=9,  # Reduced font size to prevent overlap&#10;              fontsize=11,&#10;              proportion=True,  # Show proportions instead of absolute values&#10;              impurity=True,&#10;              ax=plt.gca())&#10;&#10;    # Enhance the title&#10;    plt.title(f'{model_name}\nValidation Accuracy: {accuracy:.2%}\n' +&#10;              'Blue = Interior | Red = Exterior',&#10;              fontsize=18, fontweight='bold', pad=30)&#10;&#10;    # Add annotations at bottom with more space&#10;    plt.title(f'{model_name}\nValidation Accuracy: {accuracy:.2%}\n' +&#10;             'Decision rules based on z-score normalized features\n' +&#10;              fontsize=18, fontweight='bold', pad=20)&#10;&#10;    # Add annotations&#10;    plt.text(0.5, -0.05,&#10;    # More padding to prevent cutoff&#10;    plt.tight_layout(pad=2.0)&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight',&#10;                facecolor='white', pad_inches=0.5)&#10;&#10;    plt.tight_layout()&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')&#10;    Create a horizontal (left-to-right) decision tree for better readability.&#10;    Fixed: Extra wide format to prevent any text overlap.&#10;    &quot;&quot;&quot;&#10;    from sklearn.tree import plot_tree&#10;&#10;    # Extra wide and tall to prevent overlap&#10;    depth = clf.get_depth()&#10;    fig_width = max(35, n_leaves * 2.5)&#10;    fig_height = max(22, depth * 4.5)&#10;&#10;&#10;    fig, ax = plt.subplots(figsize=(20, 16), dpi=150, facecolor='white')&#10;&#10;    # Plot tree&#10;              precision=2,&#10;              impurity=True,&#10;              ax=ax)&#10;&#10;    # Styling&#10;    ax.set_title(f'{model_name} (Accuracy: {accuracy:.2%})\n' +&#10;              fontsize=10,&#10;                 fontsize=16, fontweight='bold', pad=20)&#10;&#10;    plt.tight_layout(pad=2.5)&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight',&#10;                facecolor='white', pad_inches=0.5)&#10;    print(f&quot;✅ Horizontal tree saved: {output_file}&quot;)&#10;    plt.close()&#10;&#10;def create_graphviz_style_tree(clf, feature_names, model_name, accuracy, output_file):&#10;    &quot;&quot;&quot;&#10;&#10;    &quot;&quot;&quot;&#10;    ax.set_title(f'{model_name} (Accuracy: {accuracy:.2%})\n' +&#10;        from sklearn.tree import export_graphviz&#10;                 fontsize=16, fontweight='bold', pad=15)&#10;&#10;    plt.tight_layout()&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')&#10;            out_file=None,&#10;            feature_names=feature_names,&#10;            class_names=['Interior', 'Exterior'],&#10;            filled=True,&#10;            rounded=True,&#10;            special_characters=True,&#10;            proportion=True,&#10;            precision=2,&#10;            impurity=True&#10;        )&#10;&#10;        # Enhance the DOT styling&#10;        dot_data = dot_data.replace('fontname=helvetica', 'fontname=&quot;Arial&quot;')&#10;        dot_data = dot_data.replace('graph [', f'graph [label=&quot;{model_name}\\nAccuracy: {accuracy:.2%}&quot;, labelloc=t, fontsize=20, ')&#10;&#10;        # Create graph&#10;        graph = pydot.graph_from_dot_data(dot_data)[0]&#10;&#10;        # Save as high-quality PNG&#10;        graph.write_png(str(output_file))&#10;        print(f&quot;✅ Graphviz-style tree saved: {output_file}&quot;)&#10;        return True&#10;&#10;    except ImportError:&#10;        print(&quot;⚠️  pydot not installed, skipping Graphviz-style visualization&quot;)&#10;        print(&quot;   Install with: pip install pydot graphviz&quot;)&#10;        return False&#10;&#10;def create_text_based_tree(clf, feature_names, model_name, output_file):&#10;    &quot;&quot;&quot;&#10;    Create a text-based representation of the decision tree.&#10;    &quot;&quot;&quot;&#10;    from sklearn.tree import export_text&#10;&#10;    tree_text = export_text(clf, feature_names=feature_names, max_depth=10)&#10;&#10;    with open(output_file, 'w') as f:&#10;        f.write(&quot;=&quot;*80 + &quot;\n&quot;)&#10;        f.write(f&quot;DECISION TREE STRUCTURE: {model_name}\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(&quot;Reading the tree:\n&quot;)&#10;        f.write(&quot;  - Each line shows a decision rule\n&quot;)&#10;        f.write(&quot;  - Indentation shows tree depth\n&quot;)&#10;        f.write(&quot;  - 'class: X' shows the predicted class at that leaf\n&quot;)&#10;        f.write(&quot;  - Values are z-scores (normalized per protein)\n&quot;)&#10;        f.write(&quot;\n&quot; + &quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(tree_text)&#10;        f.write(&quot;\n\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)&#10;        f.write(&quot;FEATURE MEANINGS:\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n&quot;)&#10;        f.write(&quot;  stride_asa_norm:       STRIDE accessible surface area (z-score)\n&quot;)&#10;        f.write(&quot;  ncps_sphere_6_norm:    Neighbor count at 6Å radius (z-score)\n&quot;)&#10;        f.write(&quot;  ncps_sphere_10_norm:   Neighbor count at 10Å radius (z-score)\n&quot;)&#10;        f.write(&quot;  ncps_sphere_6_uni_norm: Uniformity at 6Å (z-score)\n&quot;)&#10;        f.write(&quot;  ncps_sphere_10_uni_norm: Uniformity at 10Å (z-score)\n\n&quot;)&#10;        f.write(&quot;Z-score interpretation:\n&quot;)&#10;        f.write(&quot;  Positive values: Above the protein's average\n&quot;)&#10;        f.write(&quot;  Negative values: Below the protein's average\n&quot;)&#10;        f.write(&quot;  Each protein normalized separately before training\n&quot;)&#10;&#10;    print(f&quot;✅ Text-based tree saved: {output_file}&quot;)&#10;&#10;def create_feature_importance_chart(clf, feature_names, model_name, output_file):&#10;    &quot;&quot;&quot;&#10;    Create a horizontal bar chart showing feature importances.&#10;    &quot;&quot;&quot;&#10;    importances = clf.feature_importances_&#10;    indices = np.argsort(importances)[::-1]&#10;&#10;    fig, ax = plt.subplots(figsize=(10, 6), dpi=150, facecolor='white')&#10;&#10;    # Create bars&#10;    colors_grad = plt.cm.viridis(np.linspace(0.3, 0.9, len(feature_names)))&#10;    bars = ax.barh(range(len(feature_names)),&#10;                   importances[indices],&#10;                   color=colors_grad)&#10;&#10;    # Labels&#10;    ax.set_yticks(range(len(feature_names)))&#10;    ax.set_yticklabels([feature_names[i] for i in indices])&#10;    ax.set_xlabel('Importance', fontsize=12, fontweight='bold')&#10;    ax.set_title(f'Feature Importance: {model_name}',&#10;                 fontsize=14, fontweight='bold', pad=15)&#10;&#10;    # Add value labels on bars&#10;    for i, (bar, imp) in enumerate(zip(bars, importances[indices])):&#10;        ax.text(imp + 0.01, bar.get_y() + bar.get_height()/2,&#10;                f'{imp:.3f}',&#10;                va='center', fontsize=10, fontweight='bold')&#10;&#10;    ax.grid(axis='x', alpha=0.3, linestyle='--')&#10;    ax.set_xlim([0, max(importances) * 1.15])&#10;&#10;    plt.tight_layout()&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')&#10;    print(f&quot;✅ Feature importance chart saved: {output_file}&quot;)&#10;    plt.close()&#10;&#10;def visualize_all_models(df):&#10;    &quot;&quot;&quot;&#10;    Create enhanced visualizations for all three models.&#10;    &quot;&quot;&quot;&#10;    output_dir = Path('results/decision_tree/enhanced_viz')&#10;    output_dir.mkdir(exist_ok=True)&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;CREATING ENHANCED VISUALIZATIONS&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Model 1: All features&#10;    print(&quot;\n1. All Features (6Å + 10Å)...&quot;)&#10;    feature_cols_all = ['stride_asa_norm', 'ncps_sphere_6_norm', 'ncps_sphere_10_norm',&#10;                        'ncps_sphere_6_uni_norm', 'ncps_sphere_10_uni_norm']&#10;    df_clean = df[feature_cols_all + ['dssp_class']].dropna()&#10;    X_all = df_clean[feature_cols_all]&#10;    y_all = df_clean['dssp_class']&#10;&#10;    clf_all = DecisionTreeClassifier(max_depth=6, random_state=42,&#10;                                     min_samples_split=20, min_samples_leaf=10)&#10;    clf_all.fit(X_all, y_all)&#10;    acc_all = accuracy_score(y_all, clf_all.predict(X_all))&#10;&#10;    create_enhanced_tree_visualization(clf_all, feature_cols_all,&#10;                                      'Decision Tree - All Features (6Å + 10Å)',&#10;                                      acc_all,&#10;                                      output_dir / 'tree_all_features_enhanced.png')&#10;    create_horizontal_tree_visualization(clf_all, feature_cols_all,&#10;                                        'All Features',&#10;                                        acc_all,&#10;                                        output_dir / 'tree_all_features_horizontal.png')&#10;    create_text_based_tree(clf_all, feature_cols_all,&#10;                          'All Features (6Å + 10Å)',&#10;                          output_dir / 'tree_all_features_text.txt')&#10;    create_feature_importance_chart(clf_all, feature_cols_all,&#10;                                   'All Features',&#10;                                   output_dir / 'importance_all_features.png')&#10;&#10;    # Model 2: 10Å only (BEST MODEL based on CV)&#10;    print(&quot;\n2. 10Å Features Only (Best Model)...&quot;)&#10;    feature_cols_10A = ['stride_asa_norm', 'ncps_sphere_10_norm', 'ncps_sphere_10_uni_norm']&#10;    df_clean = df[feature_cols_10A + ['dssp_class']].dropna()&#10;    X_10A = df_clean[feature_cols_10A]&#10;    y_10A = df_clean['dssp_class']&#10;&#10;    clf_10A = DecisionTreeClassifier(max_depth=6, random_state=42,&#10;                                     min_samples_split=20, min_samples_leaf=10)&#10;    clf_10A.fit(X_10A, y_10A)&#10;    acc_10A = accuracy_score(y_10A, clf_10A.predict(X_10A))&#10;&#10;    create_enhanced_tree_visualization(clf_10A, feature_cols_10A,&#10;                                      'Decision Tree - 10Å Features Only (BEST MODEL)',&#10;                                      acc_10A,&#10;                                      output_dir / 'tree_10A_only_enhanced.png')&#10;    create_horizontal_tree_visualization(clf_10A, feature_cols_10A,&#10;                                        '10Å Features Only (BEST)',&#10;                                        acc_10A,&#10;                                        output_dir / 'tree_10A_only_horizontal.png')&#10;    create_text_based_tree(clf_10A, feature_cols_10A,&#10;                          '10Å Features Only (BEST MODEL)',&#10;                          output_dir / 'tree_10A_only_text.txt')&#10;    create_feature_importance_chart(clf_10A, feature_cols_10A,&#10;                                   '10Å Features Only (BEST)',&#10;                                   output_dir / 'importance_10A_only.png')&#10;&#10;    # Try Graphviz-style for the best model&#10;    create_graphviz_style_tree(clf_10A, feature_cols_10A,&#10;                               '10Å Features Only (BEST MODEL)',&#10;                               acc_10A,&#10;                               output_dir / 'tree_10A_only_graphviz.png')&#10;&#10;    # Model 3: 6Å only&#10;    print(&quot;\n3. 6Å Features Only...&quot;)&#10;    feature_cols_6A = ['stride_asa_norm', 'ncps_sphere_6_norm', 'ncps_sphere_6_uni_norm']&#10;    df_clean = df[feature_cols_6A + ['dssp_class']].dropna()&#10;    X_6A = df_clean[feature_cols_6A]&#10;    y_6A = df_clean['dssp_class']&#10;&#10;    clf_6A = DecisionTreeClassifier(max_depth=6, random_state=42,&#10;                                    min_samples_split=20, min_samples_leaf=10)&#10;    clf_6A.fit(X_6A, y_6A)&#10;    acc_6A = accuracy_score(y_6A, clf_6A.predict(X_6A))&#10;&#10;    create_enhanced_tree_visualization(clf_6A, feature_cols_6A,&#10;                                      'Decision Tree - 6Å Features Only',&#10;                                      acc_6A,&#10;                                      output_dir / 'tree_6A_only_enhanced.png')&#10;    create_horizontal_tree_visualization(clf_6A, feature_cols_6A,&#10;                                        '6Å Features Only',&#10;                                        acc_6A,&#10;                                        output_dir / 'tree_6A_only_horizontal.png')&#10;    create_text_based_tree(clf_6A, feature_cols_6A,&#10;                          '6Å Features Only',&#10;                          output_dir / 'tree_6A_only_text.txt')&#10;    create_feature_importance_chart(clf_6A, feature_cols_6A,&#10;                                   '6Å Features Only',&#10;                                   output_dir / 'importance_6A_only.png')&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;SUMMARY&quot;)&#10;    print(&quot;=&quot;*80)&#10;    print(f&quot;\nTraining Accuracy:&quot;)&#10;    print(f&quot;  All features: {acc_all:.2%}&quot;)&#10;    print(f&quot;  10Å only:     {acc_10A:.2%} ⭐ BEST (88.6% validation)&quot;)&#10;    print(f&quot;  6Å only:      {acc_6A:.2%}&quot;)&#10;&#10;    print(f&quot;\n✅ All visualizations saved in: {output_dir}/&quot;)&#10;    print(f&quot;\nGenerated files:&quot;)&#10;    print(f&quot;  - *_enhanced.png (Standard tree visualization)&quot;)&#10;    print(f&quot;  - *_horizontal.png (Wide format for presentations)&quot;)&#10;    print(f&quot;  - *_text.txt (Text-based tree structure)&quot;)&#10;    print(f&quot;  - importance_*.png (Feature importance charts)&quot;)&#10;    print(f&quot;  - tree_10A_only_graphviz.png (if pydot installed)&quot;)&#10;&#10;def main():&#10;    &quot;&quot;&quot;&#10;    Create enhanced visualizations for all decision tree models.&#10;    &quot;&quot;&quot;&#10;    print(&quot;=&quot;*80)&#10;    print(&quot;ENHANCED DECISION TREE VISUALIZATION&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Load data&#10;    df = load_normalized_data()&#10;    if df is None:&#10;        return&#10;&#10;    # Create all visualizations&#10;    visualize_all_models(df)&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;✅ ENHANCED VISUALIZATION COMPLETE!&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Enhanced Decision Tree Visualization&#10;Creates beautiful, publication-quality decision tree diagrams&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;import matplotlib.pyplot as plt&#10;import matplotlib.patches as mpatches&#10;from sklearn.tree import DecisionTreeClassifier, plot_tree&#10;from sklearn.metrics import accuracy_score&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;def load_normalized_data():&#10;    &quot;&quot;&quot;Load the pre-normalized combined dataset.&quot;&quot;&quot;&#10;    data_file = Path('results/decision_tree/combined_normalized.csv')&#10;    if not data_file.exists():&#10;        print(&quot;❌ Error: Run decision_tree_analysis.py first to generate normalized data&quot;)&#10;        return None&#10;    df = pd.read_csv(data_file)&#10;    print(f&quot;✅ Loaded normalized data: {len(df)} residues&quot;)&#10;    return df&#10;&#10;def create_enhanced_tree_visualization(clf, feature_names, model_name, accuracy, output_file):&#10;    &quot;&quot;&quot;&#10;    Create a beautiful, enhanced decision tree visualization with custom styling.&#10;    &quot;&quot;&quot;&#10;    # Set up the figure with high quality&#10;    plt.figure(figsize=(24, 14), dpi=150, facecolor='white')&#10;&#10;    # Custom color scheme - gradient from interior (blue) to exterior (orange)&#10;    colors = ['#3498db', '#e74c3c']  # Blue for interior, Red for exterior&#10;&#10;    # Plot the tree with enhanced styling&#10;    plot_tree(clf,&#10;              feature_names=feature_names,&#10;              class_names=['Interior (0)', 'Exterior (1)'],&#10;              filled=True,&#10;              rounded=True,&#10;              fontsize=9,  # Reduced font size to prevent overlap&#10;              fontsize=11,&#10;              proportion=True,  # Show proportions instead of absolute values&#10;              impurity=True,&#10;              ax=plt.gca())&#10;&#10;    # Enhance the title&#10;    plt.title(f'{model_name}\nValidation Accuracy: {accuracy:.2%}\n' +&#10;              'Blue = Interior | Red = Exterior',&#10;              fontsize=18, fontweight='bold', pad=30)&#10;&#10;    # Add annotations at bottom with more space&#10;    plt.title(f'{model_name}\nValidation Accuracy: {accuracy:.2%}\n' +&#10;             'Decision rules based on z-score normalized features\n' +&#10;              fontsize=18, fontweight='bold', pad=20)&#10;&#10;    # Add annotations&#10;    plt.text(0.5, -0.05,&#10;    # More padding to prevent cutoff&#10;    plt.tight_layout(pad=2.0)&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight',&#10;                facecolor='white', pad_inches=0.5)&#10;&#10;    plt.tight_layout()&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')&#10;    Create a horizontal (left-to-right) decision tree for better readability.&#10;    Fixed: Extra wide format to prevent any text overlap.&#10;    &quot;&quot;&quot;&#10;    from sklearn.tree import plot_tree&#10;&#10;    # Extra wide and tall to prevent overlap&#10;    depth = clf.get_depth()&#10;    fig_width = max(35, n_leaves * 2.5)&#10;    fig_height = max(22, depth * 4.5)&#10;&#10;&#10;    fig, ax = plt.subplots(figsize=(20, 16), dpi=150, facecolor='white')&#10;&#10;    # Plot tree&#10;              precision=2,&#10;              impurity=True,&#10;              ax=ax)&#10;&#10;    # Styling&#10;    ax.set_title(f'{model_name} (Accuracy: {accuracy:.2%})\n' +&#10;              fontsize=10,&#10;                 fontsize=16, fontweight='bold', pad=20)&#10;&#10;    plt.tight_layout(pad=2.5)&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight',&#10;                facecolor='white', pad_inches=0.5)&#10;    print(f&quot;✅ Horizontal tree saved: {output_file}&quot;)&#10;    plt.close()&#10;&#10;def create_graphviz_style_tree(clf, feature_names, model_name, accuracy, output_file):&#10;    &quot;&quot;&quot;&#10;&#10;    &quot;&quot;&quot;&#10;    ax.set_title(f'{model_name} (Accuracy: {accuracy:.2%})\n' +&#10;        from sklearn.tree import export_graphviz&#10;                 fontsize=16, fontweight='bold', pad=15)&#10;&#10;    plt.tight_layout()&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')&#10;            out_file=None,&#10;            feature_names=feature_names,&#10;            class_names=['Interior', 'Exterior'],&#10;            filled=True,&#10;            rounded=True,&#10;            special_characters=True,&#10;            proportion=True,&#10;            precision=2,&#10;            impurity=True&#10;        )&#10;&#10;        # Enhance the DOT styling&#10;        dot_data = dot_data.replace('fontname=helvetica', 'fontname=&quot;Arial&quot;')&#10;        dot_data = dot_data.replace('graph [', f'graph [label=&quot;{model_name}\\nAccuracy: {accuracy:.2%}&quot;, labelloc=t, fontsize=20, ')&#10;&#10;        # Create graph&#10;        graph = pydot.graph_from_dot_data(dot_data)[0]&#10;&#10;        # Save as high-quality PNG&#10;        graph.write_png(str(output_file))&#10;        print(f&quot;✅ Graphviz-style tree saved: {output_file}&quot;)&#10;        return True&#10;&#10;    except ImportError:&#10;        print(&quot;⚠️  pydot not installed, skipping Graphviz-style visualization&quot;)&#10;        print(&quot;   Install with: pip install pydot graphviz&quot;)&#10;        return False&#10;&#10;def create_text_based_tree(clf, feature_names, model_name, output_file):&#10;    &quot;&quot;&quot;&#10;    Create a text-based representation of the decision tree.&#10;    &quot;&quot;&quot;&#10;    from sklearn.tree import export_text&#10;&#10;    tree_text = export_text(clf, feature_names=feature_names, max_depth=10)&#10;&#10;    with open(output_file, 'w') as f:&#10;        f.write(&quot;=&quot;*80 + &quot;\n&quot;)&#10;        f.write(f&quot;DECISION TREE STRUCTURE: {model_name}\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(&quot;Reading the tree:\n&quot;)&#10;        f.write(&quot;  - Each line shows a decision rule\n&quot;)&#10;        f.write(&quot;  - Indentation shows tree depth\n&quot;)&#10;        f.write(&quot;  - 'class: X' shows the predicted class at that leaf\n&quot;)&#10;        f.write(&quot;  - Values are z-scores (normalized per protein)\n&quot;)&#10;        f.write(&quot;\n&quot; + &quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(tree_text)&#10;        f.write(&quot;\n\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)&#10;        f.write(&quot;FEATURE MEANINGS:\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n&quot;)&#10;        f.write(&quot;  stride_asa_norm:       STRIDE accessible surface area (z-score)\n&quot;)&#10;        f.write(&quot;  ncps_sphere_6_norm:    Neighbor count at 6Å radius (z-score)\n&quot;)&#10;        f.write(&quot;  ncps_sphere_10_norm:   Neighbor count at 10Å radius (z-score)\n&quot;)&#10;        f.write(&quot;  ncps_sphere_6_uni_norm: Uniformity at 6Å (z-score)\n&quot;)&#10;        f.write(&quot;  ncps_sphere_10_uni_norm: Uniformity at 10Å (z-score)\n\n&quot;)&#10;        f.write(&quot;Z-score interpretation:\n&quot;)&#10;        f.write(&quot;  Positive values: Above the protein's average\n&quot;)&#10;        f.write(&quot;  Negative values: Below the protein's average\n&quot;)&#10;        f.write(&quot;  Each protein normalized separately before training\n&quot;)&#10;&#10;    print(f&quot;✅ Text-based tree saved: {output_file}&quot;)&#10;&#10;def create_feature_importance_chart(clf, feature_names, model_name, output_file):&#10;    &quot;&quot;&quot;&#10;    Create a horizontal bar chart showing feature importances.&#10;    &quot;&quot;&quot;&#10;    importances = clf.feature_importances_&#10;    indices = np.argsort(importances)[::-1]&#10;&#10;    fig, ax = plt.subplots(figsize=(10, 6), dpi=150, facecolor='white')&#10;&#10;    # Create bars&#10;    colors_grad = plt.cm.viridis(np.linspace(0.3, 0.9, len(feature_names)))&#10;    bars = ax.barh(range(len(feature_names)),&#10;                   importances[indices],&#10;                   color=colors_grad)&#10;&#10;    # Labels&#10;    ax.set_yticks(range(len(feature_names)))&#10;    ax.set_yticklabels([feature_names[i] for i in indices])&#10;    ax.set_xlabel('Importance', fontsize=12, fontweight='bold')&#10;    ax.set_title(f'Feature Importance: {model_name}',&#10;                 fontsize=14, fontweight='bold', pad=15)&#10;&#10;    # Add value labels on bars&#10;    for i, (bar, imp) in enumerate(zip(bars, importances[indices])):&#10;        ax.text(imp + 0.01, bar.get_y() + bar.get_height()/2,&#10;                f'{imp:.3f}',&#10;                va='center', fontsize=10, fontweight='bold')&#10;&#10;    ax.grid(axis='x', alpha=0.3, linestyle='--')&#10;    ax.set_xlim([0, max(importances) * 1.15])&#10;&#10;    plt.tight_layout()&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')&#10;    print(f&quot;✅ Feature importance chart saved: {output_file}&quot;)&#10;    plt.close()&#10;&#10;def visualize_all_models(df):&#10;    &quot;&quot;&quot;&#10;    Create enhanced visualizations for all three models.&#10;    &quot;&quot;&quot;&#10;    output_dir = Path('results/decision_tree/enhanced_viz')&#10;    output_dir.mkdir(exist_ok=True)&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;CREATING ENHANCED VISUALIZATIONS&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Model 1: All features&#10;    # All features (6Å + 10Å) - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    feature_cols_all = ['ncps_sphere_6_norm', 'ncps_sphere_10_norm',&#10;                        'ncps_sphere_6_uni_norm', 'ncps_sphere_10_uni_norm']&#10;    df_clean = df[feature_cols_all + ['dssp_class']].dropna()&#10;    X_all = df_clean[feature_cols_all]&#10;    y_all = df_clean['dssp_class']&#10;&#10;    clf_all = DecisionTreeClassifier(max_depth=6, random_state=42,&#10;                                     min_samples_split=20, min_samples_leaf=10)&#10;    clf_all.fit(X_all, y_all)&#10;    acc_all = accuracy_score(y_all, clf_all.predict(X_all))&#10;&#10;    create_enhanced_tree_visualization(clf_all, feature_cols_all,&#10;                                      'Decision Tree - All Features (6Å + 10Å)',&#10;                                      acc_all,&#10;                                      output_dir / 'tree_all_features_enhanced.png')&#10;    create_horizontal_tree_visualization(clf_all, feature_cols_all,&#10;                                        'All Features',&#10;                                        acc_all,&#10;                                        output_dir / 'tree_all_features_horizontal.png')&#10;    create_text_based_tree(clf_all, feature_cols_all,&#10;                          'All Features (6Å + 10Å)',&#10;                          output_dir / 'tree_all_features_text.txt')&#10;    create_feature_importance_chart(clf_all, feature_cols_all,&#10;                                   'All Features',&#10;                                   output_dir / 'importance_all_features.png')&#10;&#10;    # Model 2: 10Å only (BEST MODEL) - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    print(&quot;\n2. 10Å Features Only (Best Model)...&quot;)&#10;    feature_cols_10A = ['ncps_sphere_10_norm', 'ncps_sphere_10_uni_norm']&#10;    df_clean = df[feature_cols_10A + ['dssp_class']].dropna()&#10;    X_10A = df_clean[feature_cols_10A]&#10;    y_10A = df_clean['dssp_class']&#10;&#10;    clf_10A = DecisionTreeClassifier(max_depth=6, random_state=42,&#10;                                     min_samples_split=20, min_samples_leaf=10)&#10;    clf_10A.fit(X_10A, y_10A)&#10;    acc_10A = accuracy_score(y_10A, clf_10A.predict(X_10A))&#10;&#10;    create_enhanced_tree_visualization(clf_10A, feature_cols_10A,&#10;                                      'Decision Tree - 10Å Features Only (BEST MODEL)',&#10;                                      acc_10A,&#10;                                      output_dir / 'tree_10A_only_enhanced.png')&#10;    create_horizontal_tree_visualization(clf_10A, feature_cols_10A,&#10;                                        '10Å Features Only (BEST)',&#10;                                        acc_10A,&#10;                                        output_dir / 'tree_10A_only_horizontal.png')&#10;    create_text_based_tree(clf_10A, feature_cols_10A,&#10;                          '10Å Features Only (BEST MODEL)',&#10;                          output_dir / 'tree_10A_only_text.txt')&#10;    create_feature_importance_chart(clf_10A, feature_cols_10A,&#10;                                   '10Å Features Only (BEST)',&#10;                                   output_dir / 'importance_10A_only.png')&#10;&#10;    # Try Graphviz-style for the best model&#10;    create_graphviz_style_tree(clf_10A, feature_cols_10A,&#10;                               '10Å Features Only (BEST MODEL)',&#10;                               acc_10A,&#10;                               output_dir / 'tree_10A_only_graphviz.png')&#10;&#10;    # Model 3: 6Å only - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    print(&quot;\n3. 6Å Features Only...&quot;)&#10;    feature_cols_6A = ['ncps_sphere_6_norm', 'ncps_sphere_6_uni_norm']&#10;    df_clean = df[feature_cols_6A + ['dssp_class']].dropna()&#10;    X_6A = df_clean[feature_cols_6A]&#10;    y_6A = df_clean['dssp_class']&#10;&#10;    clf_6A = DecisionTreeClassifier(max_depth=6, random_state=42,&#10;                                    min_samples_split=20, min_samples_leaf=10)&#10;    clf_6A.fit(X_6A, y_6A)&#10;    acc_6A = accuracy_score(y_6A, clf_6A.predict(X_6A))&#10;&#10;    create_enhanced_tree_visualization(clf_6A, feature_cols_6A,&#10;                                      'Decision Tree - 6Å Features Only',&#10;                                      acc_6A,&#10;                                      output_dir / 'tree_6A_only_enhanced.png')&#10;    create_horizontal_tree_visualization(clf_6A, feature_cols_6A,&#10;                                        '6Å Features Only',&#10;                                        acc_6A,&#10;                                        output_dir / 'tree_6A_only_horizontal.png')&#10;    create_text_based_tree(clf_6A, feature_cols_6A,&#10;                          '6Å Features Only',&#10;                          output_dir / 'tree_6A_only_text.txt')&#10;    create_feature_importance_chart(clf_6A, feature_cols_6A,&#10;                                   '6Å Features Only',&#10;                                   output_dir / 'importance_6A_only.png')&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;SUMMARY&quot;)&#10;    print(&quot;=&quot;*80)&#10;    print(f&quot;\nTraining Accuracy:&quot;)&#10;    print(f&quot;  All features: {acc_all:.2%}&quot;)&#10;    print(f&quot;  10Å only:     {acc_10A:.2%} ⭐ BEST (88.6% validation)&quot;)&#10;    print(f&quot;  6Å only:      {acc_6A:.2%}&quot;)&#10;&#10;    print(f&quot;\n✅ All visualizations saved in: {output_dir}/&quot;)&#10;    print(f&quot;\nGenerated files:&quot;)&#10;    print(f&quot;  - *_enhanced.png (Standard tree visualization)&quot;)&#10;    print(f&quot;  - *_horizontal.png (Wide format for presentations)&quot;)&#10;    print(f&quot;  - *_text.txt (Text-based tree structure)&quot;)&#10;    print(f&quot;  - importance_*.png (Feature importance charts)&quot;)&#10;    print(f&quot;  - tree_10A_only_graphviz.png (if pydot installed)&quot;)&#10;&#10;def main():&#10;    &quot;&quot;&quot;&#10;    Create enhanced visualizations for all decision tree models.&#10;    &quot;&quot;&quot;&#10;    print(&quot;=&quot;*80)&#10;    print(&quot;ENHANCED DECISION TREE VISUALIZATION&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Load data&#10;    df = load_normalized_data()&#10;    if df is None:&#10;        return&#10;&#10;    # Create all visualizations&#10;    visualize_all_models(df)&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;✅ ENHANCED VISUALIZATION COMPLETE!&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/create_model_development_csv.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/create_model_development_csv.py" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Create Model Development CSV Files&#10;Extracts ONLY features for model development (no DSSP/STRIDE values)&#10;Creates clean datasets with only neighbor-based features&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;&#10;def create_model_development_csv(results_dir=&quot;results&quot;):&#10;    &quot;&quot;&quot;&#10;    Create CSV files containing ONLY features for model development.&#10;    &#10;    Excludes ALL DSSP/STRIDE values:&#10;    - No dssp_asa, dssp_class, dssp_ss&#10;    - No stride_asa, stride_class, stride_ss&#10;    &#10;    Includes ONLY:&#10;    - Basic residue info (res_id, res_num, protein)&#10;    - Neighbor-based features (counts and uniformity)&#10;    &quot;&quot;&quot;&#10;    &#10;    print(&quot;=&quot;*80)&#10;    print(&quot;CREATING MODEL DEVELOPMENT CSV FILES&quot;)&#10;    print(&quot;(DSSP/STRIDE FREE - ONLY NEIGHBOR-BASED FEATURES)&quot;)&#10;    print(&quot;=&quot;*80)&#10;    &#10;    # Columns to KEEP for model development&#10;    model_columns = [&#10;        'res_id',                    # Amino acid type&#10;        'res_num',                   # Residue number&#10;        'ncps_sphere_6',             # Neighbor count at 6Å&#10;        'ncps_sphere_6_uni',         # Uniformity at 6Å&#10;        'ncps_sphere_10',            # Neighbor count at 10Å&#10;        'ncps_sphere_10_uni',        # Uniformity at 10Å&#10;        'ncps_class'                 # Your algorithm's classification&#10;    ]&#10;    &#10;    # Process individual protein files&#10;    proteins = ['3pte', '4d05', '6wti', '7upo']&#10;    individual_files = []&#10;    &#10;    for protein in proteins:&#10;        input_file = Path(results_dir) / f&quot;{protein}_results.csv&quot;&#10;        output_file = Path(results_dir) / f&quot;{protein}_model_development.csv&quot;&#10;        &#10;        if input_file.exists():&#10;            print(f&quot;\nProcessing: {protein.upper()}&quot;)&#10;            &#10;            # Read full results&#10;            df = pd.read_csv(input_file)&#10;            print(f&quot;  Input: {len(df)} residues with {len(df.columns)} columns&quot;)&#10;            &#10;            # Extract only model development columns&#10;            df_model = df[model_columns].copy()&#10;            &#10;            # Add protein identifier&#10;            df_model.insert(0, 'protein', protein.upper())&#10;            &#10;            # Save&#10;            df_model.to_csv(output_file, index=False, float_format='%.10f')&#10;            print(f&quot;  Output: {len(df_model)} residues with {len(df_model.columns)} columns&quot;)&#10;            print(f&quot;  ✅ Saved: {output_file}&quot;)&#10;            &#10;            individual_files.append((protein, output_file, df_model))&#10;        else:&#10;            print(f&quot;\n⚠️  File not found: {input_file}&quot;)&#10;    &#10;    # Create combined model development file&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;CREATING COMBINED MODEL DEVELOPMENT FILE&quot;)&#10;    print(&quot;=&quot;*80)&#10;    &#10;    combined_dfs = [df for _, _, df in individual_files]&#10;    df_combined = pd.concat(combined_dfs, ignore_index=True)&#10;    &#10;    combined_file = Path(results_dir) / &quot;combined_model_development.csv&quot;&#10;    df_combined.to_csv(combined_file, index=False, float_format='%.10f')&#10;    &#10;    print(f&quot;\nCombined dataset:&quot;)&#10;    print(f&quot;  Total residues: {len(df_combined)}&quot;)&#10;    print(f&quot;  Proteins: {df_combined['protein'].unique().tolist()}&quot;)&#10;    print(f&quot;  Features: {len(df_combined.columns)} columns&quot;)&#10;    print(f&quot;  ✅ Saved: {combined_file}&quot;)&#10;    &#10;    # Create normalized version for machine learning&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;CREATING NORMALIZED MODEL DEVELOPMENT FILE&quot;)&#10;    print(&quot;=&quot;*80)&#10;    &#10;    df_normalized = df_combined.copy()&#10;    &#10;    # Features to normalize (only neighbor-based)&#10;    features_to_normalize = [&#10;        'ncps_sphere_6',&#10;        'ncps_sphere_6_uni',&#10;        'ncps_sphere_10',&#10;        'ncps_sphere_10_uni'&#10;    ]&#10;    &#10;    # Z-score normalization per protein&#10;    for protein in df_normalized['protein'].unique():&#10;        mask = df_normalized['protein'] == protein&#10;        print(f&quot;\nNormalizing {protein}:&quot;)&#10;        &#10;        for feat in features_to_normalize:&#10;            values = df_normalized.loc[mask, feat]&#10;            if values.notna().sum() &gt; 0:&#10;                mean = values.mean()&#10;                std = values.std()&#10;                if std &gt; 0:&#10;                    df_normalized.loc[mask, f'{feat}_norm'] = (values - mean) / std&#10;                else:&#10;                    df_normalized.loc[mask, f'{feat}_norm'] = 0.0&#10;                print(f&quot;  {feat}: mean={mean:.2f}, std={std:.2f}&quot;)&#10;            else:&#10;                df_normalized.loc[mask, f'{feat}_norm'] = 0.0&#10;    &#10;    # Reorder columns: basic info, original features, normalized features, classification&#10;    column_order = [&#10;        'protein',&#10;        'res_id',&#10;        'res_num',&#10;        'ncps_sphere_6',&#10;        'ncps_sphere_6_uni',&#10;        'ncps_sphere_10',&#10;        'ncps_sphere_10_uni',&#10;        'ncps_sphere_6_norm',&#10;        'ncps_sphere_6_uni_norm',&#10;        'ncps_sphere_10_norm',&#10;        'ncps_sphere_10_uni_norm',&#10;        'ncps_class'&#10;    ]&#10;    &#10;    df_normalized = df_normalized[column_order]&#10;    &#10;    normalized_file = Path(results_dir) / &quot;combined_model_development_normalized.csv&quot;&#10;    df_normalized.to_csv(normalized_file, index=False, float_format='%.10f')&#10;    &#10;    print(f&quot;\nNormalized dataset:&quot;)&#10;    print(f&quot;  Total residues: {len(df_normalized)}&quot;)&#10;    print(f&quot;  Features: {len(df_normalized.columns)} columns&quot;)&#10;    print(f&quot;    - 4 original neighbor features&quot;)&#10;    print(f&quot;    - 4 normalized neighbor features (z-score per protein)&quot;)&#10;    print(f&quot;  ✅ Saved: {normalized_file}&quot;)&#10;    &#10;    # Generate summary&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;SUMMARY&quot;)&#10;    print(&quot;=&quot;*80)&#10;    &#10;    print(&quot;\n INDIVIDUAL PROTEIN FILES (for single-protein analysis):&quot;)&#10;    for protein, filepath, df in individual_files:&#10;        print(f&quot;  - {filepath} ({len(df)} residues)&quot;)&#10;    &#10;    print(&quot;\n COMBINED FILES (for multi-protein analysis):&quot;)&#10;    print(f&quot;  - {combined_file}&quot;)&#10;    print(f&quot;    → {len(df_combined)} residues, raw features&quot;)&#10;    print(f&quot;  - {normalized_file}&quot;)&#10;    print(f&quot;    → {len(df_normalized)} residues, z-score normalized per protein&quot;)&#10;    &#10;    print(&quot;\n✅ COLUMNS IN MODEL DEVELOPMENT FILES:&quot;)&#10;    print(&quot;  Basic Info:&quot;)&#10;    print(&quot;    - protein: Protein identifier (3PTE, 4d05, 6wti, 7upo)&quot;)&#10;    print(&quot;    - res_id: Amino acid type (ALA, LEU, etc.)&quot;)&#10;    print(&quot;    - res_num: Residue number in sequence&quot;)&#10;    print(&quot;\n  Features for Classification (Raw):&quot;)&#10;    print(&quot;    - ncps_sphere_6: Neighbor count at 6Å radius&quot;)&#10;    print(&quot;    - ncps_sphere_6_uni: Uniformity at 6Å radius&quot;)&#10;    print(&quot;    - ncps_sphere_10: Neighbor count at 10Å radius&quot;)&#10;    print(&quot;    - ncps_sphere_10_uni: Uniformity at 10Å radius&quot;)&#10;    print(&quot;\n  Features for Classification (Normalized - in normalized file only):&quot;)&#10;    print(&quot;    - ncps_sphere_6_norm: Z-score normalized neighbor count at 6Å&quot;)&#10;    print(&quot;    - ncps_sphere_6_uni_norm: Z-score normalized uniformity at 6Å&quot;)&#10;    print(&quot;    - ncps_sphere_10_norm: Z-score normalized neighbor count at 10Å&quot;)&#10;    print(&quot;    - ncps_sphere_10_uni_norm: Z-score normalized uniformity at 10Å&quot;)&#10;    print(&quot;\n  Classification Result:&quot;)&#10;    print(&quot;    - ncps_class: Your algorithm's prediction (0=interior, 1=exterior)&quot;)&#10;    &#10;    print(&quot;\n⚠️  EXCLUDED (not in these files):&quot;)&#10;    print(&quot;    - NO dssp_asa, dssp_class, dssp_ss&quot;)&#10;    print(&quot;    - NO stride_asa, stride_class, stride_ss&quot;)&#10;    print(&quot;    → Use original *_results.csv files for validation against DSSP/STRIDE&quot;)&#10;    &#10;    print(&quot;\n USAGE:&quot;)&#10;    print(&quot;  For model development/training:&quot;)&#10;    print(&quot;    → Use: combined_model_development_normalized.csv&quot;)&#10;    print(&quot;    → Features: 4 normalized features (ncps_*_norm)&quot;)&#10;    print(&quot;    → Target: ncps_class (your classification)&quot;)&#10;    print(&quot;\n  For validation against DSSP/STRIDE:&quot;)&#10;    print(&quot;    → Use: [protein]_results.csv (original files)&quot;)&#10;    print(&quot;    → Contains both model features AND reference methods&quot;)&#10;    &#10;    # Show sample of normalized file&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;SAMPLE DATA (first 5 rows from normalized file):&quot;)&#10;    print(&quot;=&quot;*80)&#10;    print(df_normalized.head(5).to_string())&#10;    &#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;✅ COMPLETE! Model development files created successfully.&quot;)&#10;    print(&quot;=&quot;*80)&#10;    &#10;    return combined_file, normalized_file&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    combined, normalized = create_model_development_csv()&#10;    print(f&quot;\n PRIMARY FILE FOR MODEL DEVELOPMENT:&quot;)&#10;    print(f&quot;   {normalized}&quot;)&#10;    print(f&quot;\n   This file contains ONLY neighbor-based features.&quot;)&#10;    print(f&quot;   NO DSSP or STRIDE values - completely agnostic!&quot;)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/cross_validation_analysis.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/cross_validation_analysis.py" />
              <option name="originalContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Cross-Validation Analysis for Decision Tree Classifier&#10;&#10;Performs k-fold cross-validation to evaluate model performance&#10;on unseen data and avoid overfitting.&#10;&#10;This validates the decision tree models built in decision_tree_analysis.py&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;import matplotlib.pyplot as plt&#10;from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.model_selection import cross_val_score, cross_validate, KFold&#10;from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;def load_normalized_data():&#10;    &quot;&quot;&quot;&#10;    Load the pre-normalized combined dataset.&#10;    &quot;&quot;&quot;&#10;    data_file = Path('results/decision_tree/combined_normalized.csv')&#10;&#10;    if not data_file.exists():&#10;        print(&quot;❌ Error: combined_normalized.csv not found!&quot;)&#10;        print(&quot;   Please run decision_tree_analysis.py first.&quot;)&#10;        return None&#10;&#10;    df = pd.read_csv(data_file)&#10;    print(f&quot;✅ Loaded normalized data: {len(df)} residues&quot;)&#10;    return df&#10;#cros validation------------------------------------------------&#10;def cross_validate_model(X, y, feature_names, model_name, n_folds=5):&#10;    &quot;&quot;&quot;&#10;    Perform k-fold cross-validation on the decision tree model.&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(f&quot;CROSS-VALIDATION: {model_name}&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Initialize model&#10;    clf = DecisionTreeClassifier(max_depth=6, random_state=42,&#10;                                  min_samples_split=20, min_samples_leaf=10)&#10;&#10;    # Define scoring metrics&#10;    scoring = {&#10;        'accuracy': make_scorer(accuracy_score),&#10;        'precision': make_scorer(precision_score, average='weighted', zero_division=0),&#10;        'recall': make_scorer(recall_score, average='weighted', zero_division=0),&#10;        'f1': make_scorer(f1_score, average='weighted', zero_division=0)&#10;    }&#10;&#10;    # K-Fold cross-validation&#10;    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)&#10;&#10;    print(f&quot;\nPerforming {n_folds}-fold cross-validation...&quot;)&#10;    print(f&quot;Dataset: {len(X)} residues&quot;)&#10;    print(f&quot;Features: {', '.join(feature_names)}&quot;)&#10;&#10;    # Perform cross-validation&#10;    cv_results = cross_validate(clf, X, y, cv=kfold, scoring=scoring,&#10;                                 return_train_score=True)&#10;&#10;    # Print results&#10;    print(&quot;\n&quot; + &quot;-&quot;*80)&#10;    print(&quot;CROSS-VALIDATION RESULTS&quot;)&#10;    print(&quot;-&quot;*80)&#10;&#10;    metrics = ['accuracy', 'precision', 'recall', 'f1']&#10;    results_summary = {}&#10;&#10;    for metric in metrics:&#10;        train_scores = cv_results[f'train_{metric}']&#10;        test_scores = cv_results[f'test_{metric}']&#10;&#10;        results_summary[metric] = {&#10;            'train_mean': train_scores.mean(),&#10;            'train_std': train_scores.std(),&#10;            'test_mean': test_scores.mean(),&#10;            'test_std': test_scores.std()&#10;        }&#10;&#10;        print(f&quot;\n{metric.upper()}:&quot;)&#10;        print(f&quot;  Training:   {train_scores.mean():.3%} ± {train_scores.std():.3%}&quot;)&#10;        print(f&quot;  Validation: {test_scores.mean():.3%} ± {test_scores.std():.3%}&quot;)&#10;        print(f&quot;  Per fold (validation): {[f'{s:.3%}' for s in test_scores]}&quot;)&#10;&#10;    # Check for overfitting&#10;    train_acc = results_summary['accuracy']['train_mean']&#10;    test_acc = results_summary['accuracy']['test_mean']&#10;    gap = train_acc - test_acc&#10;&#10;    print(&quot;\n&quot; + &quot;-&quot;*80)&#10;    print(&quot;OVERFITTING ANALYSIS&quot;)&#10;    print(&quot;-&quot;*80)&#10;    print(f&quot;Training accuracy:   {train_acc:.3%}&quot;)&#10;    print(f&quot;Validation accuracy: {test_acc:.3%}&quot;)&#10;    print(f&quot;Gap (overfitting):   {gap:.3%}&quot;)&#10;&#10;    if gap &lt; 0.05:&#10;        print(&quot;✅ Good generalization (gap &lt; 5%)&quot;)&#10;    elif gap &lt; 0.10:&#10;        print(&quot;⚠️  Slight overfitting (gap 5-10%)&quot;)&#10;    else:&#10;        print(&quot;❌ Significant overfitting (gap &gt; 10%)&quot;)&#10;&#10;    return results_summary, cv_results&#10;&#10;def compare_all_models(df):&#10;    &quot;&quot;&quot;&#10;    Compare cross-validation results for all three models.&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;COMPARING ALL MODELS WITH CROSS-VALIDATION&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    results_all_models = {}&#10;&#10;    # Model 1: All features (6Å + 10Å)&#10;    feature_cols_all = ['stride_asa_norm', 'ncps_sphere_6_norm', 'ncps_sphere_10_norm',&#10;                        'ncps_sphere_6_uni_norm', 'ncps_sphere_10_uni_norm']&#10;    df_clean = df[feature_cols_all + ['dssp_class']].dropna()&#10;    X_all = df_clean[feature_cols_all]&#10;    y_all = df_clean['dssp_class']&#10;&#10;    results_all, cv_all = cross_validate_model(X_all, y_all, feature_cols_all,&#10;                                                &quot;All Features (6Å + 10Å)&quot;, n_folds=5)&#10;    results_all_models['all'] = results_all&#10;&#10;    # Model 2: 6Å only&#10;    feature_cols_6A = ['stride_asa_norm', 'ncps_sphere_6_norm', 'ncps_sphere_6_uni_norm']&#10;    df_clean = df[feature_cols_6A + ['dssp_class']].dropna()&#10;    X_6A = df_clean[feature_cols_6A]&#10;    y_6A = df_clean['dssp_class']&#10;&#10;    results_6A, cv_6A = cross_validate_model(X_6A, y_6A, feature_cols_6A,&#10;                                              &quot;6Å Features Only&quot;, n_folds=5)&#10;    results_all_models['6A'] = results_6A&#10;&#10;    # Model 3: 10Å only&#10;    feature_cols_10A = ['stride_asa_norm', 'ncps_sphere_10_norm', 'ncps_sphere_10_uni_norm']&#10;    df_clean = df[feature_cols_10A + ['dssp_class']].dropna()&#10;    X_10A = df_clean[feature_cols_10A]&#10;    y_10A = df_clean['dssp_class']&#10;&#10;    results_10A, cv_10A = cross_validate_model(X_10A, y_10A, feature_cols_10A,&#10;                                                &quot;10Å Features Only&quot;, n_folds=5)&#10;    results_all_models['10A'] = results_10A&#10;&#10;    # Summary comparison&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;FINAL COMPARISON (VALIDATION ACCURACY)&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    acc_all = results_all_models['all']['accuracy']['test_mean']&#10;    acc_6A = results_all_models['6A']['accuracy']['test_mean']&#10;    acc_10A = results_all_models['10A']['accuracy']['test_mean']&#10;&#10;    print(f&quot;\nValidation Accuracy (5-fold CV):&quot;)&#10;    print(f&quot;  All features (6Å + 10Å): {acc_all:.3%} ± {results_all_models['all']['accuracy']['test_std']:.3%}&quot;)&#10;    print(f&quot;  6Å features only:        {acc_6A:.3%} ± {results_all_models['6A']['accuracy']['test_std']:.3%}&quot;)&#10;    print(f&quot;  10Å features only:       {acc_10A:.3%} ± {results_all_models['10A']['accuracy']['test_std']:.3%}&quot;)&#10;&#10;    # Determine best model&#10;    best_acc = max(acc_all, acc_6A, acc_10A)&#10;    if best_acc == acc_all:&#10;        best_model = &quot;All features (6Å + 10Å)&quot;&#10;    elif best_acc == acc_6A:&#10;        best_model = &quot;6Å features only&quot;&#10;    else:&#10;        best_model = &quot;10Å features only&quot;&#10;&#10;    print(f&quot;\n✅ Best model (by CV accuracy): {best_model} ({best_acc:.3%})&quot;)&#10;&#10;    # Visualize comparison&#10;    visualize_cv_comparison(results_all_models)&#10;&#10;    return results_all_models&#10;&#10;def visualize_cv_comparison(results_all_models):&#10;    &quot;&quot;&quot;&#10;    Create visualization comparing cross-validation results.&#10;    &quot;&quot;&quot;&#10;    output_dir = Path('results/decision_tree')&#10;&#10;    # Prepare data for plotting&#10;    models = ['All Features', '6Å Only', '10Å Only']&#10;    metrics = ['accuracy', 'precision', 'recall', 'f1']&#10;&#10;    test_means = {&#10;        'All Features': [results_all_models['all'][m]['test_mean'] for m in metrics],&#10;        '6Å Only': [results_all_models['6A'][m]['test_mean'] for m in metrics],&#10;        '10Å Only': [results_all_models['10A'][m]['test_mean'] for m in metrics]&#10;    }&#10;&#10;    test_stds = {&#10;        'All Features': [results_all_models['all'][m]['test_std'] for m in metrics],&#10;        '6Å Only': [results_all_models['6A'][m]['test_std'] for m in metrics],&#10;        '10Å Only': [results_all_models['10A'][m]['test_std'] for m in metrics]&#10;    }&#10;&#10;    # Create bar plot&#10;    fig, ax = plt.subplots(figsize=(12, 6))&#10;&#10;    x = np.arange(len(metrics))&#10;    width = 0.25&#10;&#10;    for i, (model, color) in enumerate(zip(models, ['#2ecc71', '#3498db', '#e74c3c'])):&#10;        offset = (i - 1) * width&#10;        ax.bar(x + offset, test_means[model], width,&#10;               yerr=test_stds[model], label=model, color=color, alpha=0.8,&#10;               capsize=5)&#10;&#10;    ax.set_xlabel('Metric', fontsize=12, fontweight='bold')&#10;    ax.set_ylabel('Score', fontsize=12, fontweight='bold')&#10;    ax.set_title('Cross-Validation Results Comparison (5-fold CV)',&#10;                 fontsize=14, fontweight='bold')&#10;    ax.set_xticks(x)&#10;    ax.set_xticklabels([m.capitalize() for m in metrics])&#10;    ax.legend()&#10;    ax.grid(axis='y', alpha=0.3)&#10;    ax.set_ylim([0, 1.0])&#10;&#10;    plt.tight_layout()&#10;    plt.savefig(output_dir / 'cross_validation_comparison.png', dpi=300, bbox_inches='tight')&#10;    print(f&quot;\n✅ Visualization saved: {output_dir / 'cross_validation_comparison.png'}&quot;)&#10;    plt.close()&#10;&#10;def save_cv_report(results_all_models):&#10;    &quot;&quot;&quot;&#10;    Save detailed cross-validation report to text file.&#10;    &quot;&quot;&quot;&#10;    output_dir = Path('results/decision_tree')&#10;    output_file = output_dir / 'cross_validation_report.txt'&#10;&#10;    with open(output_file, 'w') as f:&#10;        f.write(&quot;CROSS-VALIDATION REPORT\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(&quot;Method: 5-fold cross-validation\n&quot;)&#10;        f.write(&quot;Strategy: Normalize each protein separately, then concatenate\n\n&quot;)&#10;&#10;        for model_name, display_name in [('all', 'All Features (6Å + 10Å)'),&#10;                                         ('6A', '6Å Features Only'),&#10;                                         ('10A', '10Å Features Only')]:&#10;            results = results_all_models[model_name]&#10;&#10;            f.write(&quot;-&quot;*80 + &quot;\n&quot;)&#10;            f.write(f&quot;{display_name}\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n\n&quot;)&#10;&#10;            for metric in ['accuracy', 'precision', 'recall', 'f1']:&#10;                train_mean = results[metric]['train_mean']&#10;                train_std = results[metric]['train_std']&#10;                test_mean = results[metric]['test_mean']&#10;                test_std = results[metric]['test_std']&#10;&#10;                f.write(f&quot;{metric.upper()}:\n&quot;)&#10;                f.write(f&quot;  Training:   {train_mean:.3%} ± {train_std:.3%}\n&quot;)&#10;                f.write(f&quot;  Validation: {test_mean:.3%} ± {test_std:.3%}\n&quot;)&#10;                f.write(f&quot;  Gap:        {(train_mean - test_mean):.3%}\n\n&quot;)&#10;&#10;        # Best model summary&#10;        acc_all = results_all_models['all']['accuracy']['test_mean']&#10;        acc_6A = results_all_models['6A']['accuracy']['test_mean']&#10;        acc_10A = results_all_models['10A']['accuracy']['test_mean']&#10;&#10;        f.write(&quot;=&quot;*80 + &quot;\n&quot;)&#10;        f.write(&quot;SUMMARY\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(f&quot;Validation Accuracy:\n&quot;)&#10;        f.write(f&quot;  All features: {acc_all:.3%}\n&quot;)&#10;        f.write(f&quot;  6Å only:      {acc_6A:.3%}\n&quot;)&#10;        f.write(f&quot;  10Å only:     {acc_10A:.3%}\n\n&quot;)&#10;&#10;        best_acc = max(acc_all, acc_6A, acc_10A)&#10;        if best_acc == acc_all:&#10;            f.write(f&quot;Best model: All features (6Å + 10Å)\n&quot;)&#10;        elif best_acc == acc_6A:&#10;            f.write(f&quot;Best model: 6Å features only\n&quot;)&#10;        else:&#10;            f.write(f&quot;Best model: 10Å features only\n&quot;)&#10;&#10;    print(f&quot;✅ Report saved: {output_file}&quot;)&#10;&#10;def main():&#10;    &quot;&quot;&quot;&#10;    Main cross-validation analysis.&#10;    &quot;&quot;&quot;&#10;    print(&quot;=&quot;*80)&#10;    print(&quot;CROSS-VALIDATION ANALYSIS FOR DECISION TREE MODELS&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Load normalized data&#10;    df = load_normalized_data()&#10;    if df is None:&#10;        return&#10;&#10;    # Run cross-validation for all models&#10;    results_all_models = compare_all_models(df)&#10;&#10;    # Save report&#10;    save_cv_report(results_all_models)&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;✅ CROSS-VALIDATION COMPLETE!&quot;)&#10;    print(&quot;=&quot;*80)&#10;    print(&quot;\nOutput files:&quot;)&#10;    print(&quot;  - results/decision_tree/cross_validation_comparison.png&quot;)&#10;    print(&quot;  - results/decision_tree/cross_validation_report.txt&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Cross-Validation Analysis for Decision Tree Classifier&#10;&#10;Performs k-fold cross-validation to evaluate model performance&#10;on unseen data and avoid overfitting.&#10;&#10;This validates the decision tree models built in decision_tree_analysis.py&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;import matplotlib.pyplot as plt&#10;from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.model_selection import cross_val_score, cross_validate, KFold&#10;from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;def load_normalized_data():&#10;    &quot;&quot;&quot;&#10;    Load the pre-normalized combined dataset.&#10;    &quot;&quot;&quot;&#10;    data_file = Path('results/decision_tree/combined_normalized.csv')&#10;&#10;    if not data_file.exists():&#10;        print(&quot;❌ Error: combined_normalized.csv not found!&quot;)&#10;        print(&quot;   Please run decision_tree_analysis.py first.&quot;)&#10;        return None&#10;&#10;    df = pd.read_csv(data_file)&#10;    print(f&quot;✅ Loaded normalized data: {len(df)} residues&quot;)&#10;    return df&#10;#cros validation------------------------------------------------&#10;def cross_validate_model(X, y, feature_names, model_name, n_folds=5):&#10;    &quot;&quot;&quot;&#10;    Perform k-fold cross-validation on the decision tree model.&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(f&quot;CROSS-VALIDATION: {model_name}&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Initialize model&#10;    clf = DecisionTreeClassifier(max_depth=6, random_state=42,&#10;                                  min_samples_split=20, min_samples_leaf=10)&#10;&#10;    # Define scoring metrics&#10;    scoring = {&#10;        'accuracy': make_scorer(accuracy_score),&#10;        'precision': make_scorer(precision_score, average='weighted', zero_division=0),&#10;        'recall': make_scorer(recall_score, average='weighted', zero_division=0),&#10;        'f1': make_scorer(f1_score, average='weighted', zero_division=0)&#10;    }&#10;&#10;    # K-Fold cross-validation&#10;    kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)&#10;&#10;    print(f&quot;\nPerforming {n_folds}-fold cross-validation...&quot;)&#10;    print(f&quot;Dataset: {len(X)} residues&quot;)&#10;    print(f&quot;Features: {', '.join(feature_names)}&quot;)&#10;&#10;    # Perform cross-validation&#10;    cv_results = cross_validate(clf, X, y, cv=kfold, scoring=scoring,&#10;                                 return_train_score=True)&#10;&#10;    # Print results&#10;    print(&quot;\n&quot; + &quot;-&quot;*80)&#10;    print(&quot;CROSS-VALIDATION RESULTS&quot;)&#10;    print(&quot;-&quot;*80)&#10;&#10;    metrics = ['accuracy', 'precision', 'recall', 'f1']&#10;    results_summary = {}&#10;&#10;    for metric in metrics:&#10;        train_scores = cv_results[f'train_{metric}']&#10;        test_scores = cv_results[f'test_{metric}']&#10;&#10;        results_summary[metric] = {&#10;            'train_mean': train_scores.mean(),&#10;            'train_std': train_scores.std(),&#10;            'test_mean': test_scores.mean(),&#10;            'test_std': test_scores.std()&#10;        }&#10;&#10;        print(f&quot;\n{metric.upper()}:&quot;)&#10;        print(f&quot;  Training:   {train_scores.mean():.3%} ± {train_scores.std():.3%}&quot;)&#10;        print(f&quot;  Validation: {test_scores.mean():.3%} ± {test_scores.std():.3%}&quot;)&#10;        print(f&quot;  Per fold (validation): {[f'{s:.3%}' for s in test_scores]}&quot;)&#10;&#10;    # Check for overfitting&#10;    train_acc = results_summary['accuracy']['train_mean']&#10;    test_acc = results_summary['accuracy']['test_mean']&#10;    gap = train_acc - test_acc&#10;&#10;    print(&quot;\n&quot; + &quot;-&quot;*80)&#10;    print(&quot;OVERFITTING ANALYSIS&quot;)&#10;    print(&quot;-&quot;*80)&#10;    print(f&quot;Training accuracy:   {train_acc:.3%}&quot;)&#10;    print(f&quot;Validation accuracy: {test_acc:.3%}&quot;)&#10;    print(f&quot;Gap (overfitting):   {gap:.3%}&quot;)&#10;&#10;    if gap &lt; 0.05:&#10;        print(&quot;✅ Good generalization (gap &lt; 5%)&quot;)&#10;    elif gap &lt; 0.10:&#10;        print(&quot;⚠️  Slight overfitting (gap 5-10%)&quot;)&#10;    else:&#10;        print(&quot;❌ Significant overfitting (gap &gt; 10%)&quot;)&#10;&#10;    return results_summary, cv_results&#10;&#10;def compare_all_models(df):&#10;    &quot;&quot;&quot;&#10;    Compare cross-validation results for all three models.&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;COMPARING ALL MODELS WITH CROSS-VALIDATION&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    results_all_models = {}&#10;&#10;    # All features (6Å + 10Å) - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    feature_cols_all = ['ncps_sphere_6_norm', 'ncps_sphere_10_norm',&#10;                        'ncps_sphere_6_uni_norm', 'ncps_sphere_10_uni_norm']&#10;    df_clean = df[feature_cols_all + ['dssp_class']].dropna()&#10;    X_all = df_clean[feature_cols_all]&#10;    y_all = df_clean['dssp_class']&#10;&#10;    results_all, cv_all = cross_validate_model(X_all, y_all, feature_cols_all,&#10;                                                &quot;All Features (6Å + 10Å)&quot;, n_folds=5)&#10;    results_all_models['all'] = results_all&#10;&#10;    # Model 2: 6Å only - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    feature_cols_6A = ['ncps_sphere_6_norm', 'ncps_sphere_6_uni_norm']&#10;    df_clean = df[feature_cols_6A + ['dssp_class']].dropna()&#10;    X_6A = df_clean[feature_cols_6A]&#10;    y_6A = df_clean['dssp_class']&#10;&#10;    results_6A, cv_6A = cross_validate_model(X_6A, y_6A, feature_cols_6A,&#10;                                              &quot;6Å Features Only&quot;, n_folds=5)&#10;    results_all_models['6A'] = results_6A&#10;&#10;    # Model 3: 10Å only - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    feature_cols_10A = ['ncps_sphere_10_norm', 'ncps_sphere_10_uni_norm']&#10;    df_clean = df[feature_cols_10A + ['dssp_class']].dropna()&#10;    X_10A = df_clean[feature_cols_10A]&#10;    y_10A = df_clean['dssp_class']&#10;&#10;    results_10A, cv_10A = cross_validate_model(X_10A, y_10A, feature_cols_10A,&#10;                                                &quot;10Å Features Only&quot;, n_folds=5)&#10;    results_all_models['10A'] = results_10A&#10;&#10;    # Summary comparison&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;FINAL COMPARISON (VALIDATION ACCURACY)&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    acc_all = results_all_models['all']['accuracy']['test_mean']&#10;    acc_6A = results_all_models['6A']['accuracy']['test_mean']&#10;    acc_10A = results_all_models['10A']['accuracy']['test_mean']&#10;&#10;    print(f&quot;\nValidation Accuracy (5-fold CV):&quot;)&#10;    print(f&quot;  All features (6Å + 10Å): {acc_all:.3%} ± {results_all_models['all']['accuracy']['test_std']:.3%}&quot;)&#10;    print(f&quot;  6Å features only:        {acc_6A:.3%} ± {results_all_models['6A']['accuracy']['test_std']:.3%}&quot;)&#10;    print(f&quot;  10Å features only:       {acc_10A:.3%} ± {results_all_models['10A']['accuracy']['test_std']:.3%}&quot;)&#10;&#10;    # Determine best model&#10;    best_acc = max(acc_all, acc_6A, acc_10A)&#10;    if best_acc == acc_all:&#10;        best_model = &quot;All features (6Å + 10Å)&quot;&#10;    elif best_acc == acc_6A:&#10;        best_model = &quot;6Å features only&quot;&#10;    else:&#10;        best_model = &quot;10Å features only&quot;&#10;&#10;    print(f&quot;\n✅ Best model (by CV accuracy): {best_model} ({best_acc:.3%})&quot;)&#10;&#10;    # Visualize comparison&#10;    visualize_cv_comparison(results_all_models)&#10;&#10;    return results_all_models&#10;&#10;def visualize_cv_comparison(results_all_models):&#10;    &quot;&quot;&quot;&#10;    Create visualization comparing cross-validation results.&#10;    &quot;&quot;&quot;&#10;    output_dir = Path('results/decision_tree')&#10;&#10;    # Prepare data for plotting&#10;    models = ['All Features', '6Å Only', '10Å Only']&#10;    metrics = ['accuracy', 'precision', 'recall', 'f1']&#10;&#10;    test_means = {&#10;        'All Features': [results_all_models['all'][m]['test_mean'] for m in metrics],&#10;        '6Å Only': [results_all_models['6A'][m]['test_mean'] for m in metrics],&#10;        '10Å Only': [results_all_models['10A'][m]['test_mean'] for m in metrics]&#10;    }&#10;&#10;    test_stds = {&#10;        'All Features': [results_all_models['all'][m]['test_std'] for m in metrics],&#10;        '6Å Only': [results_all_models['6A'][m]['test_std'] for m in metrics],&#10;        '10Å Only': [results_all_models['10A'][m]['test_std'] for m in metrics]&#10;    }&#10;&#10;    # Create bar plot&#10;    fig, ax = plt.subplots(figsize=(12, 6))&#10;&#10;    x = np.arange(len(metrics))&#10;    width = 0.25&#10;&#10;    for i, (model, color) in enumerate(zip(models, ['#2ecc71', '#3498db', '#e74c3c'])):&#10;        offset = (i - 1) * width&#10;        ax.bar(x + offset, test_means[model], width,&#10;               yerr=test_stds[model], label=model, color=color, alpha=0.8,&#10;               capsize=5)&#10;&#10;    ax.set_xlabel('Metric', fontsize=12, fontweight='bold')&#10;    ax.set_ylabel('Score', fontsize=12, fontweight='bold')&#10;    ax.set_title('Cross-Validation Results Comparison (5-fold CV)',&#10;                 fontsize=14, fontweight='bold')&#10;    ax.set_xticks(x)&#10;    ax.set_xticklabels([m.capitalize() for m in metrics])&#10;    ax.legend()&#10;    ax.grid(axis='y', alpha=0.3)&#10;    ax.set_ylim([0, 1.0])&#10;&#10;    plt.tight_layout()&#10;    plt.savefig(output_dir / 'cross_validation_comparison.png', dpi=300, bbox_inches='tight')&#10;    print(f&quot;\n✅ Visualization saved: {output_dir / 'cross_validation_comparison.png'}&quot;)&#10;    plt.close()&#10;&#10;def save_cv_report(results_all_models):&#10;    &quot;&quot;&quot;&#10;    Save detailed cross-validation report to text file.&#10;    &quot;&quot;&quot;&#10;    output_dir = Path('results/decision_tree')&#10;    output_file = output_dir / 'cross_validation_report.txt'&#10;&#10;    with open(output_file, 'w') as f:&#10;        f.write(&quot;CROSS-VALIDATION REPORT\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(&quot;Method: 5-fold cross-validation\n&quot;)&#10;        f.write(&quot;Strategy: Normalize each protein separately, then concatenate\n\n&quot;)&#10;&#10;        for model_name, display_name in [('all', 'All Features (6Å + 10Å)'),&#10;                                         ('6A', '6Å Features Only'),&#10;                                         ('10A', '10Å Features Only')]:&#10;            results = results_all_models[model_name]&#10;&#10;            f.write(&quot;-&quot;*80 + &quot;\n&quot;)&#10;            f.write(f&quot;{display_name}\n&quot;)&#10;            f.write(&quot;-&quot;*80 + &quot;\n\n&quot;)&#10;&#10;            for metric in ['accuracy', 'precision', 'recall', 'f1']:&#10;                train_mean = results[metric]['train_mean']&#10;                train_std = results[metric]['train_std']&#10;                test_mean = results[metric]['test_mean']&#10;                test_std = results[metric]['test_std']&#10;&#10;                f.write(f&quot;{metric.upper()}:\n&quot;)&#10;                f.write(f&quot;  Training:   {train_mean:.3%} ± {train_std:.3%}\n&quot;)&#10;                f.write(f&quot;  Validation: {test_mean:.3%} ± {test_std:.3%}\n&quot;)&#10;                f.write(f&quot;  Gap:        {(train_mean - test_mean):.3%}\n\n&quot;)&#10;&#10;        # Best model summary&#10;        acc_all = results_all_models['all']['accuracy']['test_mean']&#10;        acc_6A = results_all_models['6A']['accuracy']['test_mean']&#10;        acc_10A = results_all_models['10A']['accuracy']['test_mean']&#10;&#10;        f.write(&quot;=&quot;*80 + &quot;\n&quot;)&#10;        f.write(&quot;SUMMARY\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(f&quot;Validation Accuracy:\n&quot;)&#10;        f.write(f&quot;  All features: {acc_all:.3%}\n&quot;)&#10;        f.write(f&quot;  6Å only:      {acc_6A:.3%}\n&quot;)&#10;        f.write(f&quot;  10Å only:     {acc_10A:.3%}\n\n&quot;)&#10;&#10;        best_acc = max(acc_all, acc_6A, acc_10A)&#10;        if best_acc == acc_all:&#10;            f.write(f&quot;Best model: All features (6Å + 10Å)\n&quot;)&#10;        elif best_acc == acc_6A:&#10;            f.write(f&quot;Best model: 6Å features only\n&quot;)&#10;        else:&#10;            f.write(f&quot;Best model: 10Å features only\n&quot;)&#10;&#10;    print(f&quot;✅ Report saved: {output_file}&quot;)&#10;&#10;def main():&#10;    &quot;&quot;&quot;&#10;    Main cross-validation analysis.&#10;    &quot;&quot;&quot;&#10;    print(&quot;=&quot;*80)&#10;    print(&quot;CROSS-VALIDATION ANALYSIS FOR DECISION TREE MODELS&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Load normalized data&#10;    df = load_normalized_data()&#10;    if df is None:&#10;        return&#10;&#10;    # Run cross-validation for all models&#10;    results_all_models = compare_all_models(df)&#10;&#10;    # Save report&#10;    save_cv_report(results_all_models)&#10;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;✅ CROSS-VALIDATION COMPLETE!&quot;)&#10;    print(&quot;=&quot;*80)&#10;    print(&quot;\nOutput files:&quot;)&#10;    print(&quot;  - results/decision_tree/cross_validation_comparison.png&quot;)&#10;    print(&quot;  - results/decision_tree/cross_validation_report.txt&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/decision_tree_zscore_analysis.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/decision_tree_zscore_analysis.py" />
              <option name="originalContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Decision Tree Analysis for Protein Burial Classification&#10;&#10;Strategy:&#10;1. Load data for each protein separately&#10;2. Normalize each protein independently (z-score per protein)&#10;3. Concatenate normalized proteins together&#10;4. Build decision tree classifier&#10;5. Visualize tree and evaluate performance&#10;&#10;Features used:&#10;- stride_asa (STRIDE accessible surface area)&#10;- ncps_sphere_6 (neighbor count at 6Å)&#10;- ncps_sphere_10 (neighbor count at 10Å)&#10;- ncps_sphere_6_uni (uniformity at 6Å)&#10;- ncps_sphere_10_uni (uniformity at 10Å)&#10;&#10;Target: dssp_class (0=interior, 1=exterior)&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;import matplotlib.pyplot as plt&#10;from sklearn.tree import DecisionTreeClassifier, plot_tree&#10;from sklearn.metrics import accuracy_score, classification_report, confusion_matrix&#10;from sklearn.model_selection import cross_val_score&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;def load_and_normalize_protein(csv_file, protein_name):&#10;    &quot;&quot;&quot;&#10;    Load protein data and normalize features using z-score.&#10;    Normalization is done PER PROTEIN to account for size differences.&#10;    &quot;&quot;&quot;&#10;    df = pd.read_csv(csv_file)&#10;&#10;    # Filter to only residues with DSSP ground truth&#10;    df = df[df['dssp_class'].notna()].copy()&#10;&#10;    print(f&quot;\n{protein_name}:&quot;)&#10;    print(f&quot;  Total residues: {len(df)}&quot;)&#10;&#10;    # Features to normalize - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    # NOTE: stride_asa and dssp_asa are NOT used for model training, only for validation&#10;    features = ['ncps_sphere_6', 'ncps_sphere_10',&#10;                'ncps_sphere_6_uni', 'ncps_sphere_10_uni']&#10;&#10;    # Z-score normalization per protein&#10;    for feat in features:&#10;        if df[feat].notna().sum() &gt; 0:&#10;            mean = df[feat].mean()&#10;            std = df[feat].std()&#10;            if std &gt; 0:&#10;                df[f'{feat}_norm'] = (df[feat] - mean) / std&#10;            else:&#10;                df[f'{feat}_norm'] = 0.0&#10;            print(f&quot;  {feat}: mean={mean:.2f}, std={std:.2f}&quot;)&#10;        else:&#10;            df[f'{feat}_norm'] = 0.0&#10;&#10;    # Add protein identifier&#10;    df['protein'] = protein_name&#10;&#10;    return df&#10;&#10;def build_decision_tree_all_features(df_combined, max_depth=5):&#10;    &quot;&quot;&quot;&#10;    Build decision tree using ALL features (6Å + 10Å).&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;DECISION TREE - ALL FEATURES (6Å + 10Å)&quot;)&#10;    print(&quot;=&quot;*80)&#10;    # Prepare features (normalized) - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    feature_cols = ['ncps_sphere_6_norm', 'ncps_sphere_10_norm',&#10;    feature_cols = ['stride_asa_norm', 'ncps_sphere_6_norm', 'ncps_sphere_10_norm',&#10;                    'ncps_sphere_6_uni_norm', 'ncps_sphere_10_uni_norm']&#10;&#10;    # Remove rows with NaN&#10;    df_clean = df_combined[feature_cols + ['dssp_class']].dropna()&#10;&#10;    X = df_clean[feature_cols]&#10;    y = df_clean['dssp_class']&#10;&#10;    print(f&quot;\nTraining on {len(X)} residues&quot;)&#10;    print(f&quot;  Interior (0): {(y==0).sum()}&quot;)&#10;    print(f&quot;  Exterior (1): {(y==1).sum()}&quot;)&#10;&#10;    # Build decision tree&#10;    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42,&#10;                                  min_samples_split=20, min_samples_leaf=10)&#10;    clf.fit(X, y)&#10;&#10;    # Predictions&#10;    y_pred = clf.predict(X)&#10;    accuracy = accuracy_score(y, y_pred)&#10;&#10;    print(f&quot;\nTraining Accuracy: {accuracy:.3%}&quot;)&#10;    print(f&quot;\nFeature Importances:&quot;)&#10;    for feat, imp in zip(feature_cols, clf.feature_importances_):&#10;        print(f&quot;  {feat:30s}: {imp:.4f}&quot;)&#10;&#10;    # Classification report&#10;    print(&quot;\nClassification Report:&quot;)&#10;    print(classification_report(y, y_pred, target_names=['Interior', 'Exterior']))&#10;&#10;    # Confusion matrix&#10;    cm = confusion_matrix(y, y_pred)&#10;    print(&quot;\nConfusion Matrix:&quot;)&#10;    print(f&quot;                  Predicted&quot;)&#10;    print(f&quot;                  Int(0)  Ext(1)&quot;)&#10;    print(f&quot;   Actual Int(0)    {cm[0,0]:4d}   {cm[0,1]:4d}&quot;)&#10;    print(f&quot;   Actual Ext(1)    {cm[1,0]:4d}   {cm[1,1]:4d}&quot;)&#10;&#10;    return clf, feature_cols, X, y&#10;&#10;def build_decision_tree_6A_only(df_combined, max_depth=5):&#10;    &quot;&quot;&quot;&#10;    Build decision tree using ONLY 6Å features.&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;DECISION TREE - 6Å FEATURES ONLY&quot;)&#10;    print(&quot;=&quot;*80)&#10;    # Features: 6Å neighbors + 6Å uniformity (DSSP/STRIDE agnostic)&#10;    feature_cols = ['ncps_sphere_6_norm', 'ncps_sphere_6_uni_norm']&#10;    feature_cols = ['stride_asa_norm', 'ncps_sphere_6_norm', 'ncps_sphere_6_uni_norm']&#10;&#10;    df_clean = df_combined[feature_cols + ['dssp_class']].dropna()&#10;&#10;    X = df_clean[feature_cols]&#10;    y = df_clean['dssp_class']&#10;&#10;    print(f&quot;\nTraining on {len(X)} residues (6Å features only)&quot;)&#10;&#10;    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42,&#10;                                  min_samples_split=20, min_samples_leaf=10)&#10;    clf.fit(X, y)&#10;&#10;    y_pred = clf.predict(X)&#10;    accuracy = accuracy_score(y, y_pred)&#10;&#10;    print(f&quot;\nTraining Accuracy: {accuracy:.3%}&quot;)&#10;    print(f&quot;\nFeature Importances:&quot;)&#10;    for feat, imp in zip(feature_cols, clf.feature_importances_):&#10;        print(f&quot;  {feat:30s}: {imp:.4f}&quot;)&#10;&#10;    print(&quot;\nClassification Report:&quot;)&#10;    print(classification_report(y, y_pred, target_names=['Interior', 'Exterior']))&#10;&#10;    cm = confusion_matrix(y, y_pred)&#10;    print(&quot;\nConfusion Matrix:&quot;)&#10;    print(f&quot;                  Predicted&quot;)&#10;    print(f&quot;                  Int(0)  Ext(1)&quot;)&#10;    print(f&quot;   Actual Int(0)    {cm[0,0]:4d}   {cm[0,1]:4d}&quot;)&#10;    print(f&quot;   Actual Ext(1)    {cm[1,0]:4d}   {cm[1,1]:4d}&quot;)&#10;&#10;    return clf, feature_cols, X, y&#10;&#10;def build_decision_tree_10A_only(df_combined, max_depth=5):&#10;    &quot;&quot;&quot;&#10;    Build decision tree using ONLY 10Å features.&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;DECISION TREE - 10Å FEATURES ONLY&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Features: stride + 10Å neighbors + 10Å uniformity&#10;    feature_cols = ['stride_asa_norm', 'ncps_sphere_10_norm', 'ncps_sphere_10_uni_norm']&#10;&#10;    df_clean = df_combined[feature_cols + ['dssp_class']].dropna()&#10;&#10;    X = df_clean[feature_cols]&#10;    y = df_clean['dssp_class']&#10;&#10;    print(f&quot;\nTraining on {len(X)} residues (10Å features only)&quot;)&#10;&#10;    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42,&#10;                                  min_samples_split=20, min_samples_leaf=10)&#10;    clf.fit(X, y)&#10;&#10;    y_pred = clf.predict(X)&#10;    accuracy = accuracy_score(y, y_pred)&#10;&#10;    print(f&quot;\nTraining Accuracy: {accuracy:.3%}&quot;)&#10;    print(f&quot;\nFeature Importances:&quot;)&#10;    for feat, imp in zip(feature_cols, clf.feature_importances_):&#10;        print(f&quot;  {feat:30s}: {imp:.4f}&quot;)&#10;&#10;    print(&quot;\nClassification Report:&quot;)&#10;    print(classification_report(y, y_pred, target_names=['Interior', 'Exterior']))&#10;&#10;    cm = confusion_matrix(y, y_pred)&#10;    print(&quot;\nConfusion Matrix:&quot;)&#10;    print(f&quot;                  Predicted&quot;)&#10;    print(f&quot;                  Int(0)  Ext(1)&quot;)&#10;    print(f&quot;   Actual Int(0)    {cm[0,0]:4d}   {cm[0,1]:4d}&quot;)&#10;    print(f&quot;   Actual Ext(1)    {cm[1,0]:4d}   {cm[1,1]:4d}&quot;)&#10;&#10;    return clf, feature_cols, X, y&#10;&#10;def visualize_decision_tree(clf, feature_names, output_file, title):&#10;    &quot;&quot;&quot;&#10;    Visualize the decision tree and save as image.&#10;    &quot;&quot;&quot;&#10;    plt.figure(figsize=(20, 10))&#10;    plot_tree(clf, feature_names=feature_names,&#10;              class_names=['Interior', 'Exterior'],&#10;              filled=True, rounded=True, fontsize=10)&#10;    plt.title(title, fontsize=16, fontweight='bold')&#10;    plt.tight_layout()&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight')&#10;    print(f&quot;\n✅ Decision tree visualization saved: {output_file}&quot;)&#10;    plt.close()&#10;&#10;def main():&#10;    &quot;&quot;&quot;&#10;    Main analysis pipeline.&#10;    &quot;&quot;&quot;&#10;    print(&quot;=&quot;*80)&#10;    print(&quot;DECISION TREE CLASSIFICATION ANALYSIS&quot;)&#10;    print(&quot;Strategy: Normalize each protein separately, then concatenate&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Load and normalize each protein separately&#10;    proteins = {&#10;        '3PTE': 'results/3PTE_results.csv',&#10;        '4d05': 'results/4d05_results.csv',&#10;        '6wti': 'results/6wti_results.csv',&#10;        '7upo': 'results/7upo_results.csv'&#10;    }&#10;&#10;    dfs = []&#10;    for name, path in proteins.items():&#10;        if Path(path).exists():&#10;            df = load_and_normalize_protein(path, name)&#10;            dfs.append(df)&#10;&#10;    # Concatenate all normalized proteins&#10;    df_combined = pd.concat(dfs, ignore_index=True)&#10;    print(f&quot;\n{'='*80}&quot;)&#10;    print(f&quot;COMBINED DATASET: {len(df_combined)} total residues&quot;)&#10;    print(f&quot;  Interior (0): {(df_combined['dssp_class']==0).sum()}&quot;)&#10;    print(f&quot;  Exterior (1): {(df_combined['dssp_class']==1).sum()}&quot;)&#10;    print(f&quot;{'='*80}&quot;)&#10;&#10;    # Save normalized combined data&#10;    output_dir = Path('results/decision_tree')&#10;    output_dir.mkdir(exist_ok=True)&#10;    df_combined.to_csv(output_dir / 'combined_normalized.csv', index=False)&#10;    print(f&quot;\n✅ Saved normalized data: {output_dir / 'combined_normalized.csv'}&quot;)&#10;&#10;    # Build decision trees with different feature sets&#10;    max_depth = 6  # Adjustable parameter&#10;&#10;    # 1. All features (6Å + 10Å)&#10;    clf_all, feat_all, X_all, y_all = build_decision_tree_all_features(df_combined, max_depth)&#10;    visualize_decision_tree(clf_all, feat_all,&#10;                           output_dir / 'decision_tree_all_features.png',&#10;                           'Decision Tree - All Features (6Å + 10Å)')&#10;&#10;    # 2. 6Å only&#10;    clf_6A, feat_6A, X_6A, y_6A = build_decision_tree_6A_only(df_combined, max_depth)&#10;    visualize_decision_tree(clf_6A, feat_6A,&#10;                           output_dir / 'decision_tree_6A_only.png',&#10;                           'Decision Tree - 6Å Features Only')&#10;&#10;    # 3. 10Å only&#10;    clf_10A, feat_10A, X_10A, y_10A = build_decision_tree_10A_only(df_combined, max_depth)&#10;    visualize_decision_tree(clf_10A, feat_10A,&#10;                           output_dir / 'decision_tree_10A_only.png',&#10;                           'Decision Tree - 10Å Features Only')&#10;&#10;    # Summary comparison&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;SUMMARY COMPARISON&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    acc_all = accuracy_score(y_all, clf_all.predict(X_all))&#10;    acc_6A = accuracy_score(y_6A, clf_6A.predict(X_6A))&#10;    acc_10A = accuracy_score(y_10A, clf_10A.predict(X_10A))&#10;&#10;    print(f&quot;\nTraining Accuracy:&quot;)&#10;    print(f&quot;  All features (6Å + 10Å): {acc_all:.3%}&quot;)&#10;    print(f&quot;  6Å features only:        {acc_6A:.3%}&quot;)&#10;    print(f&quot;  10Å features only:       {acc_10A:.3%}&quot;)&#10;&#10;    if acc_all &gt;= acc_6A and acc_all &gt;= acc_10A:&#10;        print(f&quot;\n✅ Best: All features (combining both radii)&quot;)&#10;    elif acc_6A &gt; acc_10A:&#10;        print(f&quot;\n✅ Best: 6Å features (local neighborhood more important)&quot;)&#10;    else:&#10;        print(f&quot;\n✅ Best: 10Å features (broader context more important)&quot;)&#10;&#10;    # Save summary&#10;    with open(output_dir / 'decision_tree_summary.txt', 'w') as f:&#10;        f.write(&quot;DECISION TREE CLASSIFICATION SUMMARY\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(f&quot;Total residues: {len(df_combined)}\n&quot;)&#10;        f.write(f&quot;Interior (0): {(df_combined['dssp_class']==0).sum()}\n&quot;)&#10;        f.write(f&quot;Exterior (1): {(df_combined['dssp_class']==1).sum()}\n\n&quot;)&#10;        f.write(f&quot;Training Accuracy:\n&quot;)&#10;        f.write(f&quot;  All features: {acc_all:.3%}\n&quot;)&#10;        f.write(f&quot;  6Å only:      {acc_6A:.3%}\n&quot;)&#10;        f.write(f&quot;  10Å only:     {acc_10A:.3%}\n\n&quot;)&#10;        f.write(&quot;Strategy: Each protein normalized separately (z-score),\n&quot;)&#10;        f.write(&quot;          then concatenated together for training.\n&quot;)&#10;&#10;    print(f&quot;\n✅ Summary saved: {output_dir / 'decision_tree_summary.txt'}&quot;)&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;✅ ANALYSIS COMPLETE!&quot;)&#10;    print(&quot;=&quot;*80)&#10;    print(f&quot;\nOutput files in: {output_dir}/&quot;)&#10;    print(&quot;  - combined_normalized.csv (normalized data)&quot;)&#10;    print(&quot;  - decision_tree_all_features.png&quot;)&#10;    print(&quot;  - decision_tree_6A_only.png&quot;)&#10;    print(&quot;  - decision_tree_10A_only.png&quot;)&#10;    print(&quot;  - decision_tree_summary.txt&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Decision Tree Analysis for Protein Burial Classification&#10;&#10;Strategy:&#10;1. Load data for each protein separately&#10;2. Normalize each protein independently (z-score per protein)&#10;3. Concatenate normalized proteins together&#10;4. Build decision tree classifier&#10;5. Visualize tree and evaluate performance&#10;&#10;Features used:&#10;- stride_asa (STRIDE accessible surface area)&#10;- ncps_sphere_6 (neighbor count at 6Å)&#10;- ncps_sphere_10 (neighbor count at 10Å)&#10;- ncps_sphere_6_uni (uniformity at 6Å)&#10;- ncps_sphere_10_uni (uniformity at 10Å)&#10;&#10;Target: dssp_class (0=interior, 1=exterior)&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;import matplotlib.pyplot as plt&#10;from sklearn.tree import DecisionTreeClassifier, plot_tree&#10;from sklearn.metrics import accuracy_score, classification_report, confusion_matrix&#10;from sklearn.model_selection import cross_val_score&#10;import warnings&#10;warnings.filterwarnings('ignore')&#10;&#10;def load_and_normalize_protein(csv_file, protein_name):&#10;    &quot;&quot;&quot;&#10;    Load protein data and normalize features using z-score.&#10;    Normalization is done PER PROTEIN to account for size differences.&#10;    &quot;&quot;&quot;&#10;    df = pd.read_csv(csv_file)&#10;&#10;    # Filter to only residues with DSSP ground truth&#10;    df = df[df['dssp_class'].notna()].copy()&#10;&#10;    print(f&quot;\n{protein_name}:&quot;)&#10;    print(f&quot;  Total residues: {len(df)}&quot;)&#10;&#10;    # Features to normalize - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    # NOTE: stride_asa and dssp_asa are NOT used for model training, only for validation&#10;    features = ['ncps_sphere_6', 'ncps_sphere_10',&#10;                'ncps_sphere_6_uni', 'ncps_sphere_10_uni']&#10;&#10;    # Z-score normalization per protein&#10;    for feat in features:&#10;        if df[feat].notna().sum() &gt; 0:&#10;            mean = df[feat].mean()&#10;            std = df[feat].std()&#10;            if std &gt; 0:&#10;                df[f'{feat}_norm'] = (df[feat] - mean) / std&#10;            else:&#10;                df[f'{feat}_norm'] = 0.0&#10;            print(f&quot;  {feat}: mean={mean:.2f}, std={std:.2f}&quot;)&#10;        else:&#10;            df[f'{feat}_norm'] = 0.0&#10;&#10;    # Add protein identifier&#10;    df['protein'] = protein_name&#10;&#10;    return df&#10;&#10;def build_decision_tree_all_features(df_combined, max_depth=5):&#10;    &quot;&quot;&quot;&#10;    Build decision tree using ALL features (6Å + 10Å).&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;DECISION TREE - ALL FEATURES (6Å + 10Å)&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Prepare features (normalized) - ONLY neighbor-based features (DSSP/STRIDE agnostic)&#10;    feature_cols = ['ncps_sphere_6_norm', 'ncps_sphere_10_norm',&#10;                    'ncps_sphere_6_uni_norm', 'ncps_sphere_10_uni_norm']&#10;&#10;    # Remove rows with NaN&#10;    df_clean = df_combined[feature_cols + ['dssp_class']].dropna()&#10;&#10;    X = df_clean[feature_cols]&#10;    y = df_clean['dssp_class']&#10;&#10;    print(f&quot;\nTraining on {len(X)} residues&quot;)&#10;    print(f&quot;  Interior (0): {(y==0).sum()}&quot;)&#10;    print(f&quot;  Exterior (1): {(y==1).sum()}&quot;)&#10;&#10;    # Build decision tree&#10;    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42,&#10;                                  min_samples_split=20, min_samples_leaf=10)&#10;    clf.fit(X, y)&#10;&#10;    # Predictions&#10;    y_pred = clf.predict(X)&#10;    accuracy = accuracy_score(y, y_pred)&#10;&#10;    print(f&quot;\nTraining Accuracy: {accuracy:.3%}&quot;)&#10;    print(f&quot;\nFeature Importances:&quot;)&#10;    for feat, imp in zip(feature_cols, clf.feature_importances_):&#10;        print(f&quot;  {feat:30s}: {imp:.4f}&quot;)&#10;&#10;    # Classification report&#10;    print(&quot;\nClassification Report:&quot;)&#10;    print(classification_report(y, y_pred, target_names=['Interior', 'Exterior']))&#10;&#10;    # Confusion matrix&#10;    cm = confusion_matrix(y, y_pred)&#10;    print(&quot;\nConfusion Matrix:&quot;)&#10;    print(f&quot;                  Predicted&quot;)&#10;    print(f&quot;                  Int(0)  Ext(1)&quot;)&#10;    print(f&quot;   Actual Int(0)    {cm[0,0]:4d}   {cm[0,1]:4d}&quot;)&#10;    print(f&quot;   Actual Ext(1)    {cm[1,0]:4d}   {cm[1,1]:4d}&quot;)&#10;&#10;    return clf, feature_cols, X, y&#10;&#10;def build_decision_tree_6A_only(df_combined, max_depth=5):&#10;    &quot;&quot;&quot;&#10;    Build decision tree using ONLY 6Å features.&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;DECISION TREE - 6Å FEATURES ONLY&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Features: 6Å neighbors + 6Å uniformity (DSSP/STRIDE agnostic)&#10;    feature_cols = ['ncps_sphere_6_norm', 'ncps_sphere_6_uni_norm']&#10;&#10;    df_clean = df_combined[feature_cols + ['dssp_class']].dropna()&#10;&#10;    X = df_clean[feature_cols]&#10;    y = df_clean['dssp_class']&#10;&#10;    print(f&quot;\nTraining on {len(X)} residues (6Å features only)&quot;)&#10;&#10;    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42,&#10;                                  min_samples_split=20, min_samples_leaf=10)&#10;    clf.fit(X, y)&#10;&#10;    y_pred = clf.predict(X)&#10;    accuracy = accuracy_score(y, y_pred)&#10;&#10;    print(f&quot;\nTraining Accuracy: {accuracy:.3%}&quot;)&#10;    print(f&quot;\nFeature Importances:&quot;)&#10;    for feat, imp in zip(feature_cols, clf.feature_importances_):&#10;        print(f&quot;  {feat:30s}: {imp:.4f}&quot;)&#10;&#10;    print(&quot;\nClassification Report:&quot;)&#10;    print(classification_report(y, y_pred, target_names=['Interior', 'Exterior']))&#10;&#10;    cm = confusion_matrix(y, y_pred)&#10;    print(&quot;\nConfusion Matrix:&quot;)&#10;    print(f&quot;                  Predicted&quot;)&#10;    print(f&quot;                  Int(0)  Ext(1)&quot;)&#10;    print(f&quot;   Actual Int(0)    {cm[0,0]:4d}   {cm[0,1]:4d}&quot;)&#10;    print(f&quot;   Actual Ext(1)    {cm[1,0]:4d}   {cm[1,1]:4d}&quot;)&#10;&#10;    return clf, feature_cols, X, y&#10;&#10;def build_decision_tree_10A_only(df_combined, max_depth=5):&#10;    &quot;&quot;&quot;&#10;    Build decision tree using ONLY 10Å features.&#10;    &quot;&quot;&quot;&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;DECISION TREE - 10Å FEATURES ONLY&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Features: 10Å neighbors + 10Å uniformity (DSSP/STRIDE agnostic)&#10;    feature_cols = ['ncps_sphere_10_norm', 'ncps_sphere_10_uni_norm']&#10;&#10;    df_clean = df_combined[feature_cols + ['dssp_class']].dropna()&#10;&#10;    X = df_clean[feature_cols]&#10;    y = df_clean['dssp_class']&#10;&#10;    print(f&quot;\nTraining on {len(X)} residues (10Å features only)&quot;)&#10;&#10;    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42,&#10;                                  min_samples_split=20, min_samples_leaf=10)&#10;    clf.fit(X, y)&#10;&#10;    y_pred = clf.predict(X)&#10;    accuracy = accuracy_score(y, y_pred)&#10;&#10;    print(f&quot;\nTraining Accuracy: {accuracy:.3%}&quot;)&#10;    print(f&quot;\nFeature Importances:&quot;)&#10;    for feat, imp in zip(feature_cols, clf.feature_importances_):&#10;        print(f&quot;  {feat:30s}: {imp:.4f}&quot;)&#10;&#10;    print(&quot;\nClassification Report:&quot;)&#10;    print(classification_report(y, y_pred, target_names=['Interior', 'Exterior']))&#10;&#10;    cm = confusion_matrix(y, y_pred)&#10;    print(&quot;\nConfusion Matrix:&quot;)&#10;    print(f&quot;                  Predicted&quot;)&#10;    print(f&quot;                  Int(0)  Ext(1)&quot;)&#10;    print(f&quot;   Actual Int(0)    {cm[0,0]:4d}   {cm[0,1]:4d}&quot;)&#10;    print(f&quot;   Actual Ext(1)    {cm[1,0]:4d}   {cm[1,1]:4d}&quot;)&#10;&#10;    return clf, feature_cols, X, y&#10;&#10;def visualize_decision_tree(clf, feature_names, output_file, title):&#10;    &quot;&quot;&quot;&#10;    Visualize the decision tree and save as image.&#10;    &quot;&quot;&quot;&#10;    plt.figure(figsize=(20, 10))&#10;    plot_tree(clf, feature_names=feature_names,&#10;              class_names=['Interior', 'Exterior'],&#10;              filled=True, rounded=True, fontsize=10)&#10;    plt.title(title, fontsize=16, fontweight='bold')&#10;    plt.tight_layout()&#10;    plt.savefig(output_file, dpi=300, bbox_inches='tight')&#10;    print(f&quot;\n✅ Decision tree visualization saved: {output_file}&quot;)&#10;    plt.close()&#10;&#10;def main():&#10;    &quot;&quot;&quot;&#10;    Main analysis pipeline.&#10;    &quot;&quot;&quot;&#10;    print(&quot;=&quot;*80)&#10;    print(&quot;DECISION TREE CLASSIFICATION ANALYSIS&quot;)&#10;    print(&quot;Strategy: Normalize each protein separately, then concatenate&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    # Load and normalize each protein separately&#10;    proteins = {&#10;        '3PTE': 'results/3PTE_results.csv',&#10;        '4d05': 'results/4d05_results.csv',&#10;        '6wti': 'results/6wti_results.csv',&#10;        '7upo': 'results/7upo_results.csv'&#10;    }&#10;&#10;    dfs = []&#10;    for name, path in proteins.items():&#10;        if Path(path).exists():&#10;            df = load_and_normalize_protein(path, name)&#10;            dfs.append(df)&#10;&#10;    # Concatenate all normalized proteins&#10;    df_combined = pd.concat(dfs, ignore_index=True)&#10;    print(f&quot;\n{'='*80}&quot;)&#10;    print(f&quot;COMBINED DATASET: {len(df_combined)} total residues&quot;)&#10;    print(f&quot;  Interior (0): {(df_combined['dssp_class']==0).sum()}&quot;)&#10;    print(f&quot;  Exterior (1): {(df_combined['dssp_class']==1).sum()}&quot;)&#10;    print(f&quot;{'='*80}&quot;)&#10;&#10;    # Save normalized combined data&#10;    output_dir = Path('results/decision_tree')&#10;    output_dir.mkdir(exist_ok=True)&#10;    df_combined.to_csv(output_dir / 'combined_normalized.csv', index=False)&#10;    print(f&quot;\n✅ Saved normalized data: {output_dir / 'combined_normalized.csv'}&quot;)&#10;&#10;    # Build decision trees with different feature sets&#10;    max_depth = 6  # Adjustable parameter&#10;&#10;    # 1. All features (6Å + 10Å)&#10;    clf_all, feat_all, X_all, y_all = build_decision_tree_all_features(df_combined, max_depth)&#10;    visualize_decision_tree(clf_all, feat_all,&#10;                           output_dir / 'decision_tree_all_features.png',&#10;                           'Decision Tree - All Features (6Å + 10Å)')&#10;&#10;    # 2. 6Å only&#10;    clf_6A, feat_6A, X_6A, y_6A = build_decision_tree_6A_only(df_combined, max_depth)&#10;    visualize_decision_tree(clf_6A, feat_6A,&#10;                           output_dir / 'decision_tree_6A_only.png',&#10;                           'Decision Tree - 6Å Features Only')&#10;&#10;    # 3. 10Å only&#10;    clf_10A, feat_10A, X_10A, y_10A = build_decision_tree_10A_only(df_combined, max_depth)&#10;    visualize_decision_tree(clf_10A, feat_10A,&#10;                           output_dir / 'decision_tree_10A_only.png',&#10;                           'Decision Tree - 10Å Features Only')&#10;&#10;    # Summary comparison&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;SUMMARY COMPARISON&quot;)&#10;    print(&quot;=&quot;*80)&#10;&#10;    acc_all = accuracy_score(y_all, clf_all.predict(X_all))&#10;    acc_6A = accuracy_score(y_6A, clf_6A.predict(X_6A))&#10;    acc_10A = accuracy_score(y_10A, clf_10A.predict(X_10A))&#10;&#10;    print(f&quot;\nTraining Accuracy:&quot;)&#10;    print(f&quot;  All features (6Å + 10Å): {acc_all:.3%}&quot;)&#10;    print(f&quot;  6Å features only:        {acc_6A:.3%}&quot;)&#10;    print(f&quot;  10Å features only:       {acc_10A:.3%}&quot;)&#10;&#10;    if acc_all &gt;= acc_6A and acc_all &gt;= acc_10A:&#10;        print(f&quot;\n✅ Best: All features (combining both radii)&quot;)&#10;    elif acc_6A &gt; acc_10A:&#10;        print(f&quot;\n✅ Best: 6Å features (local neighborhood more important)&quot;)&#10;    else:&#10;        print(f&quot;\n✅ Best: 10Å features (broader context more important)&quot;)&#10;&#10;    # Save summary&#10;    with open(output_dir / 'decision_tree_summary.txt', 'w') as f:&#10;        f.write(&quot;DECISION TREE CLASSIFICATION SUMMARY\n&quot;)&#10;        f.write(&quot;=&quot;*80 + &quot;\n\n&quot;)&#10;        f.write(f&quot;Total residues: {len(df_combined)}\n&quot;)&#10;        f.write(f&quot;Interior (0): {(df_combined['dssp_class']==0).sum()}\n&quot;)&#10;        f.write(f&quot;Exterior (1): {(df_combined['dssp_class']==1).sum()}\n\n&quot;)&#10;        f.write(f&quot;Training Accuracy:\n&quot;)&#10;        f.write(f&quot;  All features: {acc_all:.3%}\n&quot;)&#10;        f.write(f&quot;  6Å only:      {acc_6A:.3%}\n&quot;)&#10;        f.write(f&quot;  10Å only:     {acc_10A:.3%}\n\n&quot;)&#10;        f.write(&quot;Strategy: Each protein normalized separately (z-score),\n&quot;)&#10;        f.write(&quot;          then concatenated together for training.\n&quot;)&#10;&#10;    print(f&quot;\n✅ Summary saved: {output_dir / 'decision_tree_summary.txt'}&quot;)&#10;    print(&quot;\n&quot; + &quot;=&quot;*80)&#10;    print(&quot;✅ ANALYSIS COMPLETE!&quot;)&#10;    print(&quot;=&quot;*80)&#10;    print(f&quot;\nOutput files in: {output_dir}/&quot;)&#10;    print(&quot;  - combined_normalized.csv (normalized data)&quot;)&#10;    print(&quot;  - decision_tree_all_features.png&quot;)&#10;    print(&quot;  - decision_tree_6A_only.png&quot;)&#10;    print(&quot;  - decision_tree_10A_only.png&quot;)&#10;    print(&quot;  - decision_tree_summary.txt&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/generate_detailed_reports.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/generate_detailed_reports.py" />
              <option name="originalContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Generate Detailed Reports for Each Protein&#10;Creates formatted tables with all parameters for each PDB file&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;from pathlib import Path&#10;&#10;def generate_detailed_report(pdb_id, results_dir=&quot;results&quot;):&#10;    &quot;&quot;&quot;Generate a detailed formatted report for a single protein.&quot;&quot;&quot;&#10;&#10;    # Read the results CSV&#10;    csv_file = Path(results_dir) / f&quot;{pdb_id}_results.csv&quot;&#10;    if not csv_file.exists():&#10;        print(f&quot;⚠️  File not found: {csv_file}&quot;)&#10;        return None&#10;&#10;    df = pd.read_csv(csv_file)&#10;&#10;    # Create output file&#10;    output_file = Path(results_dir) / f&quot;{pdb_id}_detailed_report.txt&quot;&#10;&#10;    with open(output_file, 'w') as f:&#10;        # Header&#10;        f.write(&quot;=&quot; * 120 + &quot;\n&quot;)&#10;        f.write(f&quot;PROTEIN BURIAL ANALYSIS - DETAILED REPORT\n&quot;)&#10;        f.write(f&quot;PDB ID: {pdb_id.upper()}\n&quot;)&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;&#10;        # Summary statistics&#10;        f.write(&quot;SUMMARY STATISTICS\n&quot;)&#10;        f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;        f.write(f&quot;Total Residues: {len(df)}\n\n&quot;)&#10;&#10;        # DSSP statistics&#10;        if df['dssp_class'].notna().sum() &gt; 0:&#10;            dssp_exterior = df['dssp_class'].sum()&#10;            dssp_interior = len(df[df['dssp_class'].notna()]) - dssp_exterior&#10;            f.write(f&quot;DSSP Classification:\n&quot;)&#10;            f.write(f&quot;  - Exterior (1): {int(dssp_exterior)} residues\n&quot;)&#10;            f.write(f&quot;  - Interior (0): {int(dssp_interior)} residues\n\n&quot;)&#10;&#10;        # Our method statistics&#10;        ncps_exterior = df['ncps_class'].sum()&#10;        ncps_interior = len(df) - ncps_exterior&#10;        f.write(f&quot;NCPS Classification (Our Method):\n&quot;)&#10;        f.write(f&quot;  - Exterior (1): {int(ncps_exterior)} residues\n&quot;)&#10;        f.write(f&quot;  - Interior (0): {int(ncps_interior)} residues\n\n&quot;)&#10;&#10;        # Agreement with DSSP&#10;        if df['dssp_class'].notna().sum() &gt; 0:&#10;            agreement = (df['dssp_class'] == df['ncps_class']).sum()&#10;            total_with_dssp = df['dssp_class'].notna().sum()&#10;            accuracy = (agreement / total_with_dssp) * 100&#10;            f.write(f&quot;Agreement with DSSP: {accuracy:.1f}% ({agreement}/{total_with_dssp})\n\n&quot;)&#10;&#10;        # Neighbor count statistics&#10;        f.write(f&quot;Neighbor Count Statistics:\n&quot;)&#10;        f.write(f&quot;  - 6Å Sphere: Mean={df['ncps_sphere_6'].mean():.1f}, &quot;&#10;                f&quot;Median={df['ncps_sphere_6'].median():.0f}, &quot;&#10;                f&quot;Range=[{df['ncps_sphere_6'].min():.0f}-{df['ncps_sphere_6'].max():.0f}]\n&quot;)&#10;        f.write(f&quot;  - 10Å Sphere: Mean={df['ncps_sphere_10'].mean():.1f}, &quot;&#10;                f&quot;Median={df['ncps_sphere_10'].median():.0f}, &quot;&#10;                f&quot;Range=[{df['ncps_sphere_10'].min():.0f}-{df['ncps_sphere_10'].max():.0f}]\n\n&quot;)&#10;&#10;        # Uniformity statistics&#10;        f.write(f&quot;Uniformity Statistics:\n&quot;)&#10;        f.write(f&quot;  - 6Å Sphere: Mean={df['ncps_sphere_6_uni'].mean():.2f}, &quot;&#10;                f&quot;Median={df['ncps_sphere_6_uni'].median():.2f}, &quot;&#10;                f&quot;Range=[{df['ncps_sphere_6_uni'].min():.2f}-{df['ncps_sphere_6_uni'].max():.2f}]\n&quot;)&#10;        f.write(f&quot;  - 10Å Sphere: Mean={df['ncps_sphere_10_uni'].mean():.2f}, &quot;&#10;                f&quot;Median={df['ncps_sphere_10_uni'].median():.2f}, &quot;&#10;                f&quot;Range=[{df['ncps_sphere_10_uni'].min():.2f}-{df['ncps_sphere_10_uni'].max():.2f}]\n\n&quot;)&#10;&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;&#10;        # Main data table&#10;        f.write(&quot;DETAILED RESIDUE DATA\n&quot;)&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;&#10;        # Column headers&#10;        f.write(f&quot;{'Res':&gt;4} {'ID':&gt;4} {'Num':&gt;5} | {'DSSP':&gt;8} {'DSSP':&gt;6} {'DSSP':&gt;4} | &quot;&#10;                f&quot;{'STRIDE':&gt;8} {'STRIDE':&gt;6} {'STRIDE':&gt;4} | &quot;&#10;                f&quot;{'NC6':&gt;4} {'Uni6':&gt;6} {'NC10':&gt;5} {'Uni10':&gt;6} | {'NCPS':&gt;5}\n&quot;)&#10;        f.write(f&quot;{'#':&gt;4} {'':&gt;4} {'':&gt;5} | {'ASA':&gt;8} {'Class':&gt;6} {'SS':&gt;4} | &quot;&#10;                f&quot;{'ASA':&gt;8} {'Class':&gt;6} {'SS':&gt;4} | &quot;&#10;                f&quot;{'':&gt;4} {'':&gt;6} {'':&gt;5} {'':&gt;6} | {'Class':&gt;5}\n&quot;)&#10;        f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;&#10;        # Data rows&#10;        for idx, row in df.iterrows():&#10;            # Format values&#10;            res_idx = idx + 1&#10;            res_id = row['res_id'][:3] if pd.notna(row['res_id']) else '---'&#10;            res_num = int(row['res_num']) if pd.notna(row['res_num']) else 0&#10;&#10;            dssp_asa = f&quot;{row['dssp_asa']:.1f}&quot; if pd.notna(row['dssp_asa']) else '---'&#10;            dssp_class = f&quot;{int(row['dssp_class'])}&quot; if pd.notna(row['dssp_class']) else '-'&#10;            dssp_ss = row['dssp_ss'] if pd.notna(row['dssp_ss']) and row['dssp_ss'] != '' else '-'&#10;&#10;            stride_asa = f&quot;{row['stride_asa']:.1f}&quot; if pd.notna(row['stride_asa']) else '---'&#10;            stride_class = f&quot;{int(row['stride_class'])}&quot; if pd.notna(row['stride_class']) else '-'&#10;            stride_ss = row['stride_ss'] if pd.notna(row['stride_ss']) and row['stride_ss'] != '' else '-'&#10;&#10;            nc6 = int(row['ncps_sphere_6']) if pd.notna(row['ncps_sphere_6']) else 0&#10;            uni6 = f&quot;{row['ncps_sphere_6_uni']:.3f}&quot; if pd.notna(row['ncps_sphere_6_uni']) else '---'&#10;            nc10 = int(row['ncps_sphere_10']) if pd.notna(row['ncps_sphere_10']) else 0&#10;            uni10 = f&quot;{row['ncps_sphere_10_uni']:.3f}&quot; if pd.notna(row['ncps_sphere_10_uni']) else '---'&#10;&#10;            ncps_class = int(row['ncps_class']) if pd.notna(row['ncps_class']) else 0&#10;&#10;            # Write row&#10;            f.write(f&quot;{res_idx:&gt;4} {res_id:&gt;4} {res_num:&gt;5} | &quot;&#10;                   f&quot;{dssp_asa:&gt;8} {dssp_class:&gt;6} {dssp_ss:&gt;4} | &quot;&#10;                   f&quot;{stride_asa:&gt;8} {stride_class:&gt;6} {stride_ss:&gt;4} | &quot;&#10;                   f&quot;{nc6:&gt;4} {uni6:&gt;6} {nc10:&gt;5} {uni10:&gt;6} | {ncps_class:&gt;5}\n&quot;)&#10;&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;&#10;        # Legend&#10;        f.write(&quot;LEGEND:\n&quot;)&#10;        f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;        f.write(&quot;Res #     : Sequential residue number\n&quot;)&#10;        f.write(&quot;ID        : Residue amino acid code (ALA, GLN, etc.)\n&quot;)&#10;        f.write(&quot;Num       : Residue number from PDB file\n&quot;)&#10;        f.write(&quot;DSSP ASA  : DSSP accessible surface area (Ų)\n&quot;)&#10;        f.write(&quot;DSSP Class: DSSP classification (1=exterior ≥30Ų, 0=interior &lt;30Ų)\n&quot;)&#10;        f.write(&quot;DSSP SS   : DSSP secondary structure (H=helix, E=strand, C=coil, etc.)\n&quot;)&#10;        f.write(&quot;STRIDE ASA: STRIDE accessible surface area (Ų)\n&quot;)&#10;        f.write(&quot;STRIDE Class: STRIDE classification (1=exterior ≥24Ų, 0=interior &lt;24Ų)\n&quot;)&#10;        f.write(&quot;STRIDE SS : STRIDE secondary structure\n&quot;)&#10;        f.write(&quot;NC6       : Neighbor count within 6Å sphere\n&quot;)&#10;        f.write(&quot;Uni6      : Uniformity at 6Å (spherical variance, 0-1)\n&quot;)&#10;        f.write(&quot;NC10      : Neighbor count within 10Å sphere\n&quot;)&#10;        f.write(&quot;Uni10     : Uniformity at 10Å (spherical variance, 0-1)\n&quot;)&#10;        f.write(&quot;NCPS Class: Our classification (1=exterior, 0=interior)\n\n&quot;)&#10;&#10;        f.write(&quot;CLASSIFICATION PARAMETERS:\n&quot;)&#10;        f.write(&quot;  - nc6_threshold = 6 (minimum neighbors at 6Å)\n&quot;)&#10;        f.write(&quot;  - nc10_threshold = 12 (minimum neighbors at 10Å)\n&quot;)&#10;        f.write(&quot;  - uni6_threshold = 0.30 (minimum uniformity at 6Å)\n&quot;)&#10;        f.write(&quot;  - uni10_threshold = 0.60 (minimum uniformity at 10Å)\n&quot;)&#10;        f.write(&quot;  - Exterior if: NC6 &lt; 6 OR NC10 &lt; 12 OR Uni6 &lt; 0.30 OR Uni10 &lt; 0.60\n&quot;)&#10;        f.write(&quot;  - Interior otherwise\n\n&quot;)&#10;&#10;        f.write(&quot;=&quot; * 120 + &quot;\n&quot;)&#10;&#10;    return output_file&#10;&#10;def main():&#10;    &quot;&quot;&quot;Generate detailed reports for all proteins.&quot;&quot;&quot;&#10;&#10;    pdb_ids = ['3PTE', '4d05', '6wti', '7upo']&#10;&#10;    print(&quot;=&quot; * 80)&#10;    print(&quot;GENERATING DETAILED REPORTS FOR ALL PROTEINS&quot;)&#10;    print(&quot;=&quot; * 80)&#10;    print()&#10;&#10;    generated_files = []&#10;&#10;    for pdb_id in pdb_ids:&#10;        print(f&quot;Processing {pdb_id}...&quot;)&#10;        output_file = generate_detailed_report(pdb_id)&#10;&#10;        if output_file:&#10;            print(f&quot;  ✅ Generated: {output_file}&quot;)&#10;            generated_files.append(output_file)&#10;        else:&#10;            print(f&quot;  ❌ Failed to generate report&quot;)&#10;&#10;    print()&#10;    print(&quot;=&quot; * 80)&#10;    print(f&quot;✅ COMPLETE! Generated {len(generated_files)} detailed reports&quot;)&#10;    print(&quot;=&quot; * 80)&#10;    print()&#10;    print(&quot;Output files:&quot;)&#10;    for f in generated_files:&#10;        print(f&quot;  - {f}&quot;)&#10;    print()&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Generate Detailed Reports for Each Protein&#10;Creates formatted tables with all parameters for each PDB file&#10;Includes complete confusion matrices and agreement/disagreement lists&#10;&quot;&quot;&quot;&#10;&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score&#10;&#10;def generate_detailed_report(pdb_id, results_dir=&quot;results&quot;):&#10;    &quot;&quot;&quot;Generate a detailed formatted report for a single protein.&quot;&quot;&quot;&#10;&#10;    # Read the results CSV&#10;    csv_file = Path(results_dir) / f&quot;{pdb_id}_results.csv&quot;&#10;    if not csv_file.exists():&#10;        print(f&quot;⚠️  File not found: {csv_file}&quot;)&#10;        return None&#10;&#10;    df = pd.read_csv(csv_file)&#10;&#10;    # Create output file&#10;    output_file = Path(results_dir) / f&quot;{pdb_id}_detailed_report.txt&quot;&#10;&#10;    with open(output_file, 'w') as f:&#10;        # Header&#10;        f.write(&quot;=&quot; * 120 + &quot;\n&quot;)&#10;        f.write(f&quot;PROTEIN BURIAL ANALYSIS - DETAILED REPORT\n&quot;)&#10;        f.write(f&quot;PDB ID: {pdb_id.upper()}\n&quot;)&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;&#10;        # Summary statistics&#10;        f.write(&quot;SUMMARY STATISTICS\n&quot;)&#10;        f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;        f.write(f&quot;Total Residues: {len(df)}\n\n&quot;)&#10;&#10;        # DSSP statistics&#10;        if df['dssp_class'].notna().sum() &gt; 0:&#10;            dssp_exterior = int(df['dssp_class'].sum())&#10;            dssp_interior = int(len(df[df['dssp_class'].notna()]) - dssp_exterior)&#10;            f.write(f&quot;DSSP Classification:\n&quot;)&#10;            f.write(f&quot;  - Exterior (1): {dssp_exterior} residues\n&quot;)&#10;            f.write(f&quot;  - Interior (0): {dssp_interior} residues\n&quot;)&#10;            f.write(f&quot;  - DSSP Cutoff Value: ASA ≥ 25% (relative accessible surface area)\n&quot;)&#10;            f.write(f&quot;    (If ASA ≥ 25%, classified as Exterior=1; otherwise Interior=0)\n\n&quot;)&#10;        &#10;        # STRIDE statistics&#10;        if df['stride_class'].notna().sum() &gt; 0:&#10;            stride_exterior = int(df['stride_class'].sum())&#10;            stride_interior = int(len(df[df['stride_class'].notna()]) - stride_exterior)&#10;            f.write(f&quot;STRIDE Classification:\n&quot;)&#10;            f.write(f&quot;  - Exterior (1): {stride_exterior} residues\n&quot;)&#10;            f.write(f&quot;  - Interior (0): {stride_interior} residues\n&quot;)&#10;            f.write(f&quot;  - STRIDE Cutoff Value: ASA ≥ 20% (relative accessible surface area)\n&quot;)&#10;            f.write(f&quot;    (If ASA ≥ 20%, classified as Exterior=1; otherwise Interior=0)\n\n&quot;)&#10;&#10;        # Our method statistics&#10;        ncps_exterior = int(df['ncps_class'].sum())&#10;        ncps_interior = int(len(df) - ncps_exterior)&#10;        f.write(f&quot;NCPS Classification (Our Method):\n&quot;)&#10;        f.write(f&quot;  - Exterior (1): {ncps_exterior} residues\n&quot;)&#10;        f.write(f&quot;  - Interior (0): {ncps_interior} residues\n\n&quot;)&#10;&#10;        # Agreement with DSSP&#10;        if df['dssp_class'].notna().sum() &gt; 0:&#10;            df_dssp = df[df['dssp_class'].notna()].copy()&#10;            agreement_dssp = (df_dssp['dssp_class'] == df_dssp['ncps_class']).sum()&#10;            total_with_dssp = len(df_dssp)&#10;            accuracy_dssp = (agreement_dssp / total_with_dssp) * 100&#10;            f.write(f&quot;Agreement with DSSP: {accuracy_dssp:.1f}% ({agreement_dssp}/{total_with_dssp})\n&quot;)&#10;        &#10;        # Agreement with STRIDE&#10;        if df['stride_class'].notna().sum() &gt; 0:&#10;            df_stride = df[df['stride_class'].notna()].copy()&#10;            agreement_stride = (df_stride['stride_class'] == df_stride['ncps_class']).sum()&#10;            total_with_stride = len(df_stride)&#10;            accuracy_stride = (agreement_stride / total_with_stride) * 100&#10;            f.write(f&quot;Agreement with STRIDE: {accuracy_stride:.1f}% ({agreement_stride}/{total_with_stride})\n\n&quot;)&#10;        else:&#10;            f.write(&quot;\n&quot;)&#10;&#10;        # Neighbor count statistics&#10;        f.write(f&quot;Neighbor Count Statistics:\n&quot;)&#10;        f.write(f&quot;  - 6Å Sphere: Mean={df['ncps_sphere_6'].mean():.1f}, &quot;&#10;                f&quot;Median={df['ncps_sphere_6'].median():.0f}, &quot;&#10;                f&quot;Range=[{df['ncps_sphere_6'].min():.0f}-{df['ncps_sphere_6'].max():.0f}]\n&quot;)&#10;        f.write(f&quot;  - 10Å Sphere: Mean={df['ncps_sphere_10'].mean():.1f}, &quot;&#10;                f&quot;Median={df['ncps_sphere_10'].median():.0f}, &quot;&#10;                f&quot;Range=[{df['ncps_sphere_10'].min():.0f}-{df['ncps_sphere_10'].max():.0f}]\n\n&quot;)&#10;&#10;        # Uniformity statistics&#10;        f.write(f&quot;Uniformity Statistics:\n&quot;)&#10;        f.write(f&quot;  - 6Å Sphere: Mean={df['ncps_sphere_6_uni'].mean():.2f}, &quot;&#10;                f&quot;Median={df['ncps_sphere_6_uni'].median():.2f}, &quot;&#10;                f&quot;Range=[{df['ncps_sphere_6_uni'].min():.2f}-{df['ncps_sphere_6_uni'].max():.2f}]\n&quot;)&#10;        f.write(f&quot;  - 10Å Sphere: Mean={df['ncps_sphere_10_uni'].mean():.2f}, &quot;&#10;                f&quot;Median={df['ncps_sphere_10_uni'].median():.2f}, &quot;&#10;                f&quot;Range=[{df['ncps_sphere_10_uni'].min():.2f}-{df['ncps_sphere_10_uni'].max():.2f}]\n\n&quot;)&#10;&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;&#10;        # Main data table&#10;        f.write(&quot;DETAILED RESIDUE DATA\n&quot;)&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;&#10;        # Column headers&#10;        f.write(f&quot;{'Res':&gt;4} {'ID':&gt;4} {'Num':&gt;5} | {'DSSP':&gt;8} {'DSSP':&gt;6} {'DSSP':&gt;4} | &quot;&#10;                f&quot;{'STRIDE':&gt;8} {'STRIDE':&gt;6} {'STRIDE':&gt;4} | &quot;&#10;                f&quot;{'NC6':&gt;4} {'Uni6':&gt;6} {'NC10':&gt;5} {'Uni10':&gt;6} | {'NCPS':&gt;5}\n&quot;)&#10;        f.write(f&quot;{'#':&gt;4} {'':&gt;4} {'':&gt;5} | {'ASA':&gt;8} {'Class':&gt;6} {'SS':&gt;4} | &quot;&#10;                f&quot;{'ASA':&gt;8} {'Class':&gt;6} {'SS':&gt;4} | &quot;&#10;                f&quot;{'':&gt;4} {'':&gt;6} {'':&gt;5} {'':&gt;6} | {'Class':&gt;5}\n&quot;)&#10;        f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;&#10;        # Data rows&#10;        for idx, row in df.iterrows():&#10;            # Format values&#10;            res_idx = idx + 1&#10;            res_id = row['res_id'][:3] if pd.notna(row['res_id']) else '---'&#10;            res_num = int(row['res_num']) if pd.notna(row['res_num']) else 0&#10;&#10;            dssp_asa = f&quot;{row['dssp_asa']:.1f}&quot; if pd.notna(row['dssp_asa']) else '---'&#10;            dssp_class = f&quot;{int(row['dssp_class'])}&quot; if pd.notna(row['dssp_class']) else '-'&#10;            dssp_ss = row['dssp_ss'] if pd.notna(row['dssp_ss']) and row['dssp_ss'] != '' else '-'&#10;&#10;            stride_asa = f&quot;{row['stride_asa']:.1f}&quot; if pd.notna(row['stride_asa']) else '---'&#10;            stride_class = f&quot;{int(row['stride_class'])}&quot; if pd.notna(row['stride_class']) else '-'&#10;            stride_ss = row['stride_ss'] if pd.notna(row['stride_ss']) and row['stride_ss'] != '' else '-'&#10;&#10;            nc6 = int(row['ncps_sphere_6']) if pd.notna(row['ncps_sphere_6']) else 0&#10;            uni6 = f&quot;{row['ncps_sphere_6_uni']:.3f}&quot; if pd.notna(row['ncps_sphere_6_uni']) else '---'&#10;            nc10 = int(row['ncps_sphere_10']) if pd.notna(row['ncps_sphere_10']) else 0&#10;            uni10 = f&quot;{row['ncps_sphere_10_uni']:.3f}&quot; if pd.notna(row['ncps_sphere_10_uni']) else '---'&#10;&#10;            ncps_class = int(row['ncps_class']) if pd.notna(row['ncps_class']) else 0&#10;&#10;            # Write row&#10;            f.write(f&quot;{res_idx:&gt;4} {res_id:&gt;4} {res_num:&gt;5} | &quot;&#10;                   f&quot;{dssp_asa:&gt;8} {dssp_class:&gt;6} {dssp_ss:&gt;4} | &quot;&#10;                   f&quot;{stride_asa:&gt;8} {stride_class:&gt;6} {stride_ss:&gt;4} | &quot;&#10;                   f&quot;{nc6:&gt;4} {uni6:&gt;6} {nc10:&gt;5} {uni10:&gt;6} | {ncps_class:&gt;5}\n&quot;)&#10;&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;&#10;        # Legend&#10;        f.write(&quot;LEGEND:\n&quot;)&#10;        f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;        f.write(&quot;Res #     : Sequential residue number\n&quot;)&#10;        f.write(&quot;ID        : Residue amino acid code (ALA, GLN, etc.)\n&quot;)&#10;        f.write(&quot;Num       : Residue number from PDB file\n&quot;)&#10;        f.write(&quot;DSSP ASA  : DSSP accessible surface area (Ų)\n&quot;)&#10;        f.write(&quot;DSSP Class: DSSP classification (1=exterior ≥30Ų, 0=interior &lt;30Ų)\n&quot;)&#10;        f.write(&quot;DSSP SS   : DSSP secondary structure (H=helix, E=strand, C=coil, etc.)\n&quot;)&#10;        f.write(&quot;STRIDE ASA: STRIDE accessible surface area (Ų)\n&quot;)&#10;        f.write(&quot;STRIDE Class: STRIDE classification (1=exterior ≥24Ų, 0=interior &lt;24Ų)\n&quot;)&#10;        f.write(&quot;STRIDE SS : STRIDE secondary structure\n&quot;)&#10;        f.write(&quot;NC6       : Neighbor count within 6Å sphere\n&quot;)&#10;        f.write(&quot;Uni6      : Uniformity at 6Å (spherical variance, 0-1)\n&quot;)&#10;        f.write(&quot;NC10      : Neighbor count within 10Å sphere\n&quot;)&#10;        f.write(&quot;Uni10     : Uniformity at 10Å (spherical variance, 0-1)\n&quot;)&#10;        f.write(&quot;NCPS Class: Our classification (1=exterior, 0=interior)\n\n&quot;)&#10;&#10;        f.write(&quot;CLASSIFICATION PARAMETERS:\n&quot;)&#10;        f.write(&quot;  - nc6_threshold = 6 (minimum neighbors at 6Å)\n&quot;)&#10;        f.write(&quot;  - nc10_threshold = 12 (minimum neighbors at 10Å)\n&quot;)&#10;        f.write(&quot;  - uni6_threshold = 0.30 (minimum uniformity at 6Å)\n&quot;)&#10;        f.write(&quot;  - uni10_threshold = 0.60 (minimum uniformity at 10Å)\n&quot;)&#10;        f.write(&quot;  - Exterior if: NC6 &lt; 6 OR NC10 &lt; 12 OR Uni6 &lt; 0.30 OR Uni10 &lt; 0.60\n&quot;)&#10;        f.write(&quot;  - Interior otherwise\n\n&quot;)&#10;&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;        &#10;        # ==================== STATISTICS SECTION ====================&#10;        f.write(&quot;STATISTICS\n&quot;)&#10;        f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;        &#10;        # DSSP Statistics&#10;        if df['dssp_class'].notna().sum() &gt; 0:&#10;            df_dssp = df[df['dssp_class'].notna()].copy()&#10;            y_true_dssp = df_dssp['dssp_class'].astype(int)&#10;            y_pred_dssp = df_dssp['ncps_class'].astype(int)&#10;            &#10;            f.write(&quot;ACCORDING TO DSSP (Ground Truth = DSSP Classifications):\n&quot;)&#10;            f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;            &#10;            # Confusion Matrix&#10;            cm_dssp = confusion_matrix(y_true_dssp, y_pred_dssp)&#10;            tn, fp, fn, tp = cm_dssp.ravel()&#10;            &#10;            f.write(&quot;CONFUSION MATRIX:\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n&quot;)&#10;            f.write(f&quot;{'':20} | {'Predicted Interior (0)':&gt;20} | {'Predicted Exterior (1)':&gt;20} |\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n&quot;)&#10;            f.write(f&quot;{'True Interior (0)':20} | {tn:&gt;20} | {fp:&gt;20} | {tn+fp:&gt;10}\n&quot;)&#10;            f.write(f&quot;{'True Exterior (1)':20} | {fn:&gt;20} | {tp:&gt;20} | {fn+tp:&gt;10}\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n&quot;)&#10;            f.write(f&quot;{'Total':20} | {tn+fn:&gt;20} | {fp+tp:&gt;20} | {tn+fp+fn+tp:&gt;10}\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n\n&quot;)&#10;            &#10;            f.write(&quot;CONFUSION MATRIX INTERPRETATION:\n&quot;)&#10;            f.write(f&quot;  - True Negatives (TN):  {tn:4d} - Correctly predicted as Interior (both DSSP and NCPS agree on Interior)\n&quot;)&#10;            f.write(f&quot;  - False Positives (FP): {fp:4d} - Incorrectly predicted as Exterior (DSSP=Interior, NCPS=Exterior)\n&quot;)&#10;            f.write(f&quot;  - False Negatives (FN): {fn:4d} - Incorrectly predicted as Interior (DSSP=Exterior, NCPS=Interior)\n&quot;)&#10;            f.write(f&quot;  - True Positives (TP):  {tp:4d} - Correctly predicted as Exterior (both DSSP and NCPS agree on Exterior)\n\n&quot;)&#10;            &#10;            # Metrics&#10;            acc_dssp = accuracy_score(y_true_dssp, y_pred_dssp)&#10;            prec_dssp = precision_score(y_true_dssp, y_pred_dssp, average='weighted', zero_division=0)&#10;            rec_dssp = recall_score(y_true_dssp, y_pred_dssp, average='weighted', zero_division=0)&#10;            f1_dssp = f1_score(y_true_dssp, y_pred_dssp, average='weighted', zero_division=0)&#10;            &#10;            # Per-class metrics&#10;            prec_per_class = precision_score(y_true_dssp, y_pred_dssp, average=None, zero_division=0)&#10;            rec_per_class = recall_score(y_true_dssp, y_pred_dssp, average=None, zero_division=0)&#10;            f1_per_class = f1_score(y_true_dssp, y_pred_dssp, average=None, zero_division=0)&#10;            &#10;            f.write(&quot;PERFORMANCE METRICS:\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n&quot;)&#10;            f.write(f&quot;  Overall Accuracy:              {acc_dssp:6.2%} ({int(acc_dssp*len(y_true_dssp))}/{len(y_true_dssp)})\n&quot;)&#10;            f.write(f&quot;  Weighted Precision:            {prec_dssp:6.2%}\n&quot;)&#10;            f.write(f&quot;  Weighted Recall:               {rec_dssp:6.2%}\n&quot;)&#10;            f.write(f&quot;  Weighted F1-Score:             {f1_dssp:6.2%}\n\n&quot;)&#10;            &#10;            f.write(&quot;PER-CLASS METRICS:\n&quot;)&#10;            f.write(f&quot;  Interior (0) - Precision:      {prec_per_class[0]:6.2%}\n&quot;)&#10;            f.write(f&quot;  Interior (0) - Recall:         {rec_per_class[0]:6.2%}\n&quot;)&#10;            f.write(f&quot;  Interior (0) - F1-Score:       {f1_per_class[0]:6.2%}\n\n&quot;)&#10;            f.write(f&quot;  Exterior (1) - Precision:      {prec_per_class[1]:6.2%}\n&quot;)&#10;            f.write(f&quot;  Exterior (1) - Recall:         {rec_per_class[1]:6.2%}\n&quot;)&#10;            f.write(f&quot;  Exterior (1) - F1-Score:       {f1_per_class[1]:6.2%}\n\n&quot;)&#10;            &#10;            f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;        &#10;        # STRIDE Statistics&#10;        if df['stride_class'].notna().sum() &gt; 0:&#10;            df_stride = df[df['stride_class'].notna()].copy()&#10;            y_true_stride = df_stride['stride_class'].astype(int)&#10;            y_pred_stride = df_stride['ncps_class'].astype(int)&#10;            &#10;            f.write(&quot;ACCORDING TO STRIDE (Ground Truth = STRIDE Classifications):\n&quot;)&#10;            f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;            &#10;            # Confusion Matrix&#10;            cm_stride = confusion_matrix(y_true_stride, y_pred_stride)&#10;            tn, fp, fn, tp = cm_stride.ravel()&#10;            &#10;            f.write(&quot;CONFUSION MATRIX:\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n&quot;)&#10;            f.write(f&quot;{'':20} | {'Predicted Interior (0)':&gt;20} | {'Predicted Exterior (1)':&gt;20} |\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n&quot;)&#10;            f.write(f&quot;{'True Interior (0)':20} | {tn:&gt;20} | {fp:&gt;20} | {tn+fp:&gt;10}\n&quot;)&#10;            f.write(f&quot;{'True Exterior (1)':20} | {fn:&gt;20} | {tp:&gt;20} | {fn+tp:&gt;10}\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n&quot;)&#10;            f.write(f&quot;{'Total':20} | {tn+fn:&gt;20} | {fp+tp:&gt;20} | {tn+fp+fn+tp:&gt;10}\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n\n&quot;)&#10;            &#10;            f.write(&quot;CONFUSION MATRIX INTERPRETATION:\n&quot;)&#10;            f.write(f&quot;  - True Negatives (TN):  {tn:4d} - Correctly predicted as Interior (both STRIDE and NCPS agree on Interior)\n&quot;)&#10;            f.write(f&quot;  - False Positives (FP): {fp:4d} - Incorrectly predicted as Exterior (STRIDE=Interior, NCPS=Exterior)\n&quot;)&#10;            f.write(f&quot;  - False Negatives (FN): {fn:4d} - Incorrectly predicted as Interior (STRIDE=Exterior, NCPS=Interior)\n&quot;)&#10;            f.write(f&quot;  - True Positives (TP):  {tp:4d} - Correctly predicted as Exterior (both STRIDE and NCPS agree on Exterior)\n\n&quot;)&#10;            &#10;            # Metrics&#10;            acc_stride = accuracy_score(y_true_stride, y_pred_stride)&#10;            prec_stride = precision_score(y_true_stride, y_pred_stride, average='weighted', zero_division=0)&#10;            rec_stride = recall_score(y_true_stride, y_pred_stride, average='weighted', zero_division=0)&#10;            f1_stride = f1_score(y_true_stride, y_pred_stride, average='weighted', zero_division=0)&#10;            &#10;            # Per-class metrics&#10;            prec_per_class = precision_score(y_true_stride, y_pred_stride, average=None, zero_division=0)&#10;            rec_per_class = recall_score(y_true_stride, y_pred_stride, average=None, zero_division=0)&#10;            f1_per_class = f1_score(y_true_stride, y_pred_stride, average=None, zero_division=0)&#10;            &#10;            f.write(&quot;PERFORMANCE METRICS:\n&quot;)&#10;            f.write(&quot;-&quot; * 60 + &quot;\n&quot;)&#10;            f.write(f&quot;  Overall Accuracy:              {acc_stride:6.2%} ({int(acc_stride*len(y_true_stride))}/{len(y_true_stride)})\n&quot;)&#10;            f.write(f&quot;  Weighted Precision:            {prec_stride:6.2%}\n&quot;)&#10;            f.write(f&quot;  Weighted Recall:               {rec_stride:6.2%}\n&quot;)&#10;            f.write(f&quot;  Weighted F1-Score:             {f1_stride:6.2%}\n\n&quot;)&#10;            &#10;            f.write(&quot;PER-CLASS METRICS:\n&quot;)&#10;            f.write(f&quot;  Interior (0) - Precision:      {prec_per_class[0]:6.2%}\n&quot;)&#10;            f.write(f&quot;  Interior (0) - Recall:         {rec_per_class[0]:6.2%}\n&quot;)&#10;            f.write(f&quot;  Interior (0) - F1-Score:       {f1_per_class[0]:6.2%}\n\n&quot;)&#10;            f.write(f&quot;  Exterior (1) - Precision:      {prec_per_class[1]:6.2%}\n&quot;)&#10;            f.write(f&quot;  Exterior (1) - Recall:         {rec_per_class[1]:6.2%}\n&quot;)&#10;            f.write(f&quot;  Exterior (1) - F1-Score:       {f1_per_class[1]:6.2%}\n\n&quot;)&#10;            &#10;            f.write(&quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;        &#10;        # ==================== AGREEMENT/DISAGREEMENT LISTS ====================&#10;        &#10;        # DSSP Agreement/Disagreement&#10;        if df['dssp_class'].notna().sum() &gt; 0:&#10;            df_dssp = df[df['dssp_class'].notna()].copy()&#10;            &#10;            # Agreement&#10;            df_agree_dssp = df_dssp[df_dssp['dssp_class'] == df_dssp['ncps_class']].copy()&#10;            f.write(&quot;RESIDUE LIST IN AGREEMENT: NCPS-DSSP\n&quot;)&#10;            f.write(&quot;=&quot; * 120 + &quot;\n&quot;)&#10;            f.write(f&quot;Total: {len(df_agree_dssp)} residues agree\n\n&quot;)&#10;            &#10;            if len(df_agree_dssp) &gt; 0:&#10;                f.write(f&quot;{'Res#':&gt;5} {'ID':&gt;4} {'Num':&gt;5} | {'Class':&gt;6} | {'DSSP ASA':&gt;9} {'NCPS NC6':&gt;9} {'NCPS NC10':&gt;10} {'NCPS Uni6':&gt;10} {'NCPS Uni10':&gt;11}\n&quot;)&#10;                f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;                for idx, row in df_agree_dssp.iterrows():&#10;                    res_idx = df.index.get_loc(idx) + 1&#10;                    class_str = &quot;Interior&quot; if row['dssp_class'] == 0 else &quot;Exterior&quot;&#10;                    f.write(f&quot;{res_idx:&gt;5} {row['res_id']:&gt;4} {int(row['res_num']):&gt;5} | {class_str:&gt;8} | &quot;&#10;                           f&quot;{row['dssp_asa']:&gt;8.1f} {int(row['ncps_sphere_6']):&gt;9} {int(row['ncps_sphere_10']):&gt;10} &quot;&#10;                           f&quot;{row['ncps_sphere_6_uni']:&gt;10.3f} {row['ncps_sphere_10_uni']:&gt;11.3f}\n&quot;)&#10;            f.write(&quot;\n&quot; + &quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;            &#10;            # Disagreement&#10;            df_disagree_dssp = df_dssp[df_dssp['dssp_class'] != df_dssp['ncps_class']].copy()&#10;            f.write(&quot;RESIDUE LIST IN DISAGREEMENT: NCPS-DSSP\n&quot;)&#10;            f.write(&quot;=&quot; * 120 + &quot;\n&quot;)&#10;            f.write(f&quot;Total: {len(df_disagree_dssp)} residues disagree\n\n&quot;)&#10;            &#10;            if len(df_disagree_dssp) &gt; 0:&#10;                f.write(f&quot;{'Res#':&gt;5} {'ID':&gt;4} {'Num':&gt;5} | {'DSSP':&gt;8} {'NCPS':&gt;8} | {'DSSP ASA':&gt;9} {'NCPS NC6':&gt;9} {'NCPS NC10':&gt;10} {'NCPS Uni6':&gt;10} {'NCPS Uni10':&gt;11}\n&quot;)&#10;                f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;                for idx, row in df_disagree_dssp.iterrows():&#10;                    res_idx = df.index.get_loc(idx) + 1&#10;                    dssp_str = &quot;Interior&quot; if row['dssp_class'] == 0 else &quot;Exterior&quot;&#10;                    ncps_str = &quot;Interior&quot; if row['ncps_class'] == 0 else &quot;Exterior&quot;&#10;                    f.write(f&quot;{res_idx:&gt;5} {row['res_id']:&gt;4} {int(row['res_num']):&gt;5} | {dssp_str:&gt;8} {ncps_str:&gt;8} | &quot;&#10;                           f&quot;{row['dssp_asa']:&gt;8.1f} {int(row['ncps_sphere_6']):&gt;9} {int(row['ncps_sphere_10']):&gt;10} &quot;&#10;                           f&quot;{row['ncps_sphere_6_uni']:&gt;10.3f} {row['ncps_sphere_10_uni']:&gt;11.3f}\n&quot;)&#10;            f.write(&quot;\n&quot; + &quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;        &#10;        # STRIDE Agreement/Disagreement&#10;        if df['stride_class'].notna().sum() &gt; 0:&#10;            df_stride = df[df['stride_class'].notna()].copy()&#10;            &#10;            # Agreement&#10;            df_agree_stride = df_stride[df_stride['stride_class'] == df_stride['ncps_class']].copy()&#10;            f.write(&quot;RESIDUE LIST IN AGREEMENT: NCPS-STRIDE\n&quot;)&#10;            f.write(&quot;=&quot; * 120 + &quot;\n&quot;)&#10;            f.write(f&quot;Total: {len(df_agree_stride)} residues agree\n\n&quot;)&#10;            &#10;            if len(df_agree_stride) &gt; 0:&#10;                f.write(f&quot;{'Res#':&gt;5} {'ID':&gt;4} {'Num':&gt;5} | {'Class':&gt;6} | {'STRIDE ASA':&gt;11} {'NCPS NC6':&gt;9} {'NCPS NC10':&gt;10} {'NCPS Uni6':&gt;10} {'NCPS Uni10':&gt;11}\n&quot;)&#10;                f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;                for idx, row in df_agree_stride.iterrows():&#10;                    res_idx = df.index.get_loc(idx) + 1&#10;                    class_str = &quot;Interior&quot; if row['stride_class'] == 0 else &quot;Exterior&quot;&#10;                    f.write(f&quot;{res_idx:&gt;5} {row['res_id']:&gt;4} {int(row['res_num']):&gt;5} | {class_str:&gt;8} | &quot;&#10;                           f&quot;{row['stride_asa']:&gt;10.1f} {int(row['ncps_sphere_6']):&gt;9} {int(row['ncps_sphere_10']):&gt;10} &quot;&#10;                           f&quot;{row['ncps_sphere_6_uni']:&gt;10.3f} {row['ncps_sphere_10_uni']:&gt;11.3f}\n&quot;)&#10;            f.write(&quot;\n&quot; + &quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;            &#10;            # Disagreement&#10;            df_disagree_stride = df_stride[df_stride['stride_class'] != df_stride['ncps_class']].copy()&#10;            f.write(&quot;RESIDUE LIST IN DISAGREEMENT: NCPS-STRIDE\n&quot;)&#10;            f.write(&quot;=&quot; * 120 + &quot;\n&quot;)&#10;            f.write(f&quot;Total: {len(df_disagree_stride)} residues disagree\n\n&quot;)&#10;            &#10;            if len(df_disagree_stride) &gt; 0:&#10;                f.write(f&quot;{'Res#':&gt;5} {'ID':&gt;4} {'Num':&gt;5} | {'STRIDE':&gt;8} {'NCPS':&gt;8} | {'STRIDE ASA':&gt;11} {'NCPS NC6':&gt;9} {'NCPS NC10':&gt;10} {'NCPS Uni6':&gt;10} {'NCPS Uni10':&gt;11}\n&quot;)&#10;                f.write(&quot;-&quot; * 120 + &quot;\n&quot;)&#10;                for idx, row in df_disagree_stride.iterrows():&#10;                    res_idx = df.index.get_loc(idx) + 1&#10;                    stride_str = &quot;Interior&quot; if row['stride_class'] == 0 else &quot;Exterior&quot;&#10;                    ncps_str = &quot;Interior&quot; if row['ncps_class'] == 0 else &quot;Exterior&quot;&#10;                    f.write(f&quot;{res_idx:&gt;5} {row['res_id']:&gt;4} {int(row['res_num']):&gt;5} | {stride_str:&gt;8} {ncps_str:&gt;8} | &quot;&#10;                           f&quot;{row['stride_asa']:&gt;10.1f} {int(row['ncps_sphere_6']):&gt;9} {int(row['ncps_sphere_10']):&gt;10} &quot;&#10;                           f&quot;{row['ncps_sphere_6_uni']:&gt;10.3f} {row['ncps_sphere_10_uni']:&gt;11.3f}\n&quot;)&#10;            f.write(&quot;\n&quot; + &quot;=&quot; * 120 + &quot;\n\n&quot;)&#10;&#10;        f.write(&quot;=&quot; * 120 + &quot;\n&quot;)&#10;&#10;    return output_file&#10;&#10;def main():&#10;    &quot;&quot;&quot;Generate detailed reports for all proteins.&quot;&quot;&quot;&#10;&#10;    pdb_ids = ['3PTE', '4d05', '6wti', '7upo']&#10;&#10;    print(&quot;=&quot; * 80)&#10;    print(&quot;GENERATING DETAILED REPORTS FOR ALL PROTEINS&quot;)&#10;    print(&quot;=&quot; * 80)&#10;    print()&#10;&#10;    generated_files = []&#10;&#10;    for pdb_id in pdb_ids:&#10;        print(f&quot;Processing {pdb_id}...&quot;)&#10;        output_file = generate_detailed_report(pdb_id)&#10;&#10;        if output_file:&#10;            print(f&quot;  ✅ Generated: {output_file}&quot;)&#10;            generated_files.append(output_file)&#10;        else:&#10;            print(f&quot;  ❌ Failed to generate report&quot;)&#10;&#10;    print()&#10;    print(&quot;=&quot; * 80)&#10;    print(f&quot;✅ COMPLETE! Generated {len(generated_files)} detailed reports&quot;)&#10;    print(&quot;=&quot; * 80)&#10;    print()&#10;    print(&quot;Output files:&quot;)&#10;    for f in generated_files:&#10;        print(f&quot;  - {f}&quot;)&#10;    print()&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>